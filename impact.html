<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-111495058-1">
  </script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-111495058-1');
  </script>
  <!-- Title -->
  <title>
    FDB Research
  </title>
  <!-- Required Meta Tags Always Come First -->
  <meta charset="utf-8" />
  <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport" />
  <meta content="ie=edge" http-equiv="x-ua-compatible" />
  <!-- Favicon -->
  <link href="apple-touch-icon.png" rel="apple-touch-icon" sizes="180x180" />
  <link href="favicon-32x32.png" rel="icon" sizes="32x32" type="image/png" />
  <link href="favicon-16x16.png" rel="icon" sizes="16x16" type="image/png" />
  <link href="manifest.json" rel="manifest" />
  <link color="#4270a9" href="safari-pinned-tab.svg" rel="mask-icon" />
  <meta content="#ffffff" name="theme-color" />
  <meta
    content="Factorised,Factorized,Factorised Databases,Factorized Databases,join,query,FDB,FDBResearch,Databases,CS,Compression,Worst-case optimal,Zurich,University of Zurich,Computer Science,Test of Time"
    name="keywords" />
  <meta content="We investigate foundational and systems aspects of factorized data processing and machine learning"
    name="description" />
  <!-- Google Fonts -->
  <!-- <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Open+Sans%3A400%2C300%2C500%2C600%2C700%7CPlayfair+Display%7CRoboto%7CRaleway%7CSpectral%7CRubik"> -->
  <!-- CSS Global Compulsory -->
  <link href="assets/vendor/bootstrap/bootstrap.min.css" rel="stylesheet" />
  <!-- CSS Global Icons -->
  <link href="assets/vendor/icon-awesome/css/font-awesome.min.css" rel="stylesheet" />
  <link href="assets/vendor/icon-line/css/simple-line-icons.css" rel="stylesheet" />
  <link href="assets/vendor/icon-etlinefont/style.css" rel="stylesheet" />
  <link href="assets/vendor/icon-line-pro/style.css" rel="stylesheet" />
  <link href="assets/vendor/icon-hs/style.css" rel="stylesheet" />
  <link href="assets/vendor/cubeportfolio-full/cubeportfolio/css/cubeportfolio.min.css" rel="stylesheet" />
  <link href="assets/vendor/animate.css" rel="stylesheet" />
  <link href="assets/vendor/hs-megamenu/src/hs.megamenu.css" rel="stylesheet" />
  <link href="assets/vendor/hamburgers/hamburgers.min.css" rel="stylesheet" />
  <link href="assets/vendor/slick-carousel/slick/slick.css" rel="stylesheet" />
  <!-- CSS Unify -->
  <link href="assets/css/unify-core.css" rel="stylesheet" />
  <link href="assets/css/unify-components.css" rel="stylesheet" />
  <link href="assets/css/unify-globals.css" rel="stylesheet" />
  <!-- CSS Customization -->
  <link href="assets/css/custom.css" rel="stylesheet" />
  <script type="text/x-mathjax-config">
   MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"
    type="text/javascript">
    </script>
</head>

<body>
  <main>
    <!-- Header -->
    <header class="u-header u-header--static u-shadow-v19" id="js-header">
      <div class="u-header__section u-header__section--light g-bg-white g-transition-0_3 g-py-10">
        <nav class="js-mega-menu navbar navbar-expand-lg">
          <div class="container">
            <!-- Responsive Toggle Button -->
            <button aria-controls="navBar" aria-expanded="false" aria-label="Toggle navigation"
              class="navbar-toggler navbar-toggler-right btn g-line-height-1 g-brd-none g-pa-0 g-pos-abs g-top-3 g-right-0"
              data-target="#navBar" data-toggle="collapse" type="button">
              <span class="hamburger hamburger--slider">
                <span class="hamburger-box">
                  <span class="hamburger-inner">
                  </span>
                </span>
              </span>
            </button>
            <!-- End Responsive Toggle Button -->
            <!-- Logo -->
            <a class="navbar-brand" href="index.html">
              <img alt="Image Description" height="40px" src="assets/img/logo/logo-fdb.png" />
            </a>
            <!-- End Logo -->
            <!-- Navigation -->
            <div class="collapse navbar-collapse align-items-center flex-sm-row g-pt-10 g-pt-5--lg g-mr-40--lg"
              id="navBar">
              <ul class="navbar-nav text-uppercase g-pos-rel g-font-weight-600 ml-auto">
                <!-- Projects -->
                <li class="nav-item hs-has-sub-menu g-mx-10--lg g-mx-15--xl" data-animation-in="fadeIn"
                  data-animation-out="fadeOut">
                  <a aria-controls="nav-submenu--features" aria-expanded="false" aria-haspopup="true"
                    class="nav-link g-py-7 g-px-0" href="#" id="nav-link--features">
                    News
                  </a>
                  <ul aria-labelledby="nav-link--features"
                    class="hs-sub-menu list-unstyled u-shadow-v11 g-brd-top g-brd-primary g-brd-top-2 g-min-width-220 g-mt-21 g-mt-11--lg--scrolling"
                    id="nav-submenu--features">
                    <li class="dropdown-item">
                      <a class="nav-link" href="retreat2023.html">
                        Retreat 2023
                      </a>
                    </li>
                    <li class="dropdown-item">
                      <a class="nav-link" href="FDBworkshop2022.html">
                        FDB Workshop 2022
                      </a>
                    </li>
                    <li class="dropdown-item">
                      <a class="nav-link" href="visitors.html">
                        Visitors
                      </a>
                    </li>
                    <li class="dropdown-item">
                      <a class="nav-link" href="events.html">
                        Events
                      </a>
                    </li>
                    <li class="dropdown-item">
                      <a class="nav-link" href="awards.html">
                        Awards
                      </a>
                    </li>
                  </ul>
                </li>
                <!-- End Projects -->
                <li class="nav-item g-mx-10--lg g-mx-15--xl">
                  <a class="nav-link g-py-7 g-px-0" href="people.html">
                    People
                  </a>
                </li>
                <!-- Projects -->
                <li class="nav-item hs-has-sub-menu g-mx-10--lg g-mx-15--xl" data-animation-in="fadeIn"
                  data-animation-out="fadeOut">
                  <a aria-controls="nav-submenu--features" aria-expanded="false" aria-haspopup="true"
                    class="nav-link g-py-7 g-px-0" href="#" id="nav-link--features">
                    Projects
                  </a>
                  <ul aria-labelledby="nav-link--features"
                    class="hs-sub-menu list-unstyled u-shadow-v11 g-brd-top g-brd-primary g-brd-top-2 g-min-width-220 g-mt-21 g-mt-11--lg--scrolling"
                    id="nav-submenu--features">
                    <li class="dropdown-item">
                      <a class="nav-link" href="principles.html">
                        Principles of Factorised Databases
                      </a>
                    </li>
                    <li class="dropdown-item">
                      <a class="nav-link" href="analytics.html">
                        In-Database Analytics
                      </a>
                    </li>
                    <li class="dropdown-item">
                      <a class="nav-link" href="ivm.html">
                        Real-time analytics over fast and continuously evolving relational data
                      </a>
                    </li>
                    <li class="dropdown-item">
                      <a class="nav-link" href="ivme.html">
                        The Complexity of Incremental View Maintenance
                      </a>
                    </li>
                  </ul>
                </li>
                <!-- End Projects -->
                <li class="nav-item g-mx-10--lg g-mx-15--xl">
                  <a class="nav-link g-py-7 g-px-0" href="publications.html">
                    Publications
                  </a>
                </li>
                <!-- Code -->
                <li class="nav-item hs-has-sub-menu g-mx-10--lg g-mx-15--xl" data-animation-in="fadeIn"
                  data-animation-out="fadeOut">
                  <a aria-controls="nav-submenu--features" aria-expanded="false" aria-haspopup="true"
                    class="nav-link g-py-7 g-px-0" href="#" id="nav-link--features">
                    Code
                  </a>
                  <ul aria-labelledby="nav-link--features"
                    class="hs-sub-menu list-unstyled u-shadow-v11 g-brd-top g-brd-primary g-brd-top-2 g-min-width-220 g-mt-21 g-mt-11--lg--scrolling"
                    id="nav-submenu--features">
                    <li class="dropdown-item">
                      <a class="nav-link" href="fivm-code.html">
                        FIVM
                      </a>
                    </li>
                    <li class="dropdown-item">
                      <a class="nav-link" href="fbench-code.html">
                        FBENCH
                      </a>
                    </li>
                  </ul>
                </li>
                <!-- End Code -->
                <li class="nav-item g-mx-10--lg g-mx-15--xl">
                  <a class="nav-link g-py-7 g-px-0" href="talks.html">
                    Talks
                  </a>
                </li>
                <li class="nav-item g-mx-10--lg g-mx-15--xl">
                  <a class="nav-link g-py-7 g-px-0" href="videos.html">
                    Videos
                  </a>
                </li>
                <li class="nav-item g-mx-10--lg g-mx-15--xl">
                  <a class="nav-link g-py-7 g-px-0" href="acknowledgements.html">
                    ACK
                  </a>
                </li>
                <li class="nav-item g-mx-10--lg g-mx-15--xl">
                  <a class="nav-link g-py-7 g-px-0" href="contacts.html">
                    Contact
                  </a>
                </li>
              </ul>
            </div>
            <!-- End Navigation -->
          </div>
        </nav>
      </div>
    </header>
    <!-- End Header -->
    <!-- Breadcrumbs -->
    <section class="g-bg-gray-light-v5 g-py-50">
      <div class="container">
        <div class="d-sm-flex text-center">
          <div class="align-self-center">
            <h2 class="h2 g-font-weight-300 w-100 g-mb-10 g-mb-0--md">
              Ten Years of Factorized Databases: A 2022 Review of their Impact
            </h2>
          </div>
          <!--div class="align-self-center ml-auto">
            <div class="px-4">
              <ul class="u-list-inline">
                <li class="list-inline-item g-mr-5">
                  <a class="u-link-v5 g-color-main g-color-primary--hover" href="customer-order-price.html">Example</a>
                  <i class="g-color-gray-light-v2 g-ml-5">/</i>
                </li>
                <li class="list-inline-item g-mr-5">
                  <a class="u-link-v5 g-color-main g-color-primary--hover" href="#publications">Publications</a>
                </li>
              </ul>
            </div>
          </div-->
        </div>
      </div>
    </section>
    <!-- End Breadcrumbs -->
    <div class="g-pt-50">
    </div>
    <!-- Blog Minimal Blocks -->
    <div class="container g-pb-20">
      <!-- <div class="row"> -->
      <div class="row">
        <!-- <div class="col-lg-1 g-mb-80"></div> -->
        <div class="col-lg-1"></div>
        <!-- Articles Content -->
        <div class="col-lg-10 g-mb-50 g-mb-0--lg">
          <article class="g-mb-60">
            <div class="text-center g-width-60x--md mx-auto g-my-40">
              <h3 class="text-uppercase g-color-primary">
                The work that started factorized databases
              </h3>
            </div>
            <div class="g-font-size-18 g-color-black-opacity-1_0 g-line-height-1_6 g-mb-30">
              <p class="g-color-black-opacity-0_8">
                The International Conference on Database Theory (ICDT) 2012 paper <strong class="g-color-primary">[
                  <citation style="display:none;">DBLP:CONF/ICDT/OLTEANUZ12</citation>]
                </strong> and its extended
                version published in the ACM Transactions on Database Systems (TODS) 2015 journal <strong
                  class="g-color-primary">[<citation style="display:none;">DBLP:journals/tods/OlteanuZ15</citation>
                  ]</strong>, both by Olteanu and Z&aacute;vodn&yacute;, put forward two basic yet fundamental
                observations:
              </p>
              <ul>
                <li>
                  <div><em>The relational representation of the answers to conjunctive queries entail redundancy that
                      can be systematically avoided by a succinct and lossless <strong>factorized</strong>
                      representation.</em></div>
                </li>
                <li>
                  <div><em>This factorized representation can be computed directly from the input database and in time
                      proportional to its size and the input size.</em></div>
                </li>
              </ul>
              <p>
                Such factorized representations give a proper balance between compactness (elimination of redundancy)
                and efficiency. Subsequent work by the same authors also showed that a host of computations can be
                performed directly on the factorized representation, so without the need to de-factorize the represented
                data.
              </p>
              <p>
                A factorized representation can be viewed as a relational algebra query that involves data values and
                only two operators: union and Cartesian product. We also refer generally to such representations as
                <em>factorized databases.</em>
                They are a special form of compression: they factorize data akin to the factorization of polynomials,
                e.g.,
              <div class="text-center"><em>a*x + a*y + b*x + b*y = (a+b)* (x+y)</em>.</div>
              Data factorization is orthogonal to value-based compression, such as run-length encoding; the two can be
              combined to achieve an even greater compression factor.
              </p>
              <p>
                This initial work also gives effective tools for managing such factorized representations, including:
              </p>
              <ul>
                <li>representation systems, </li>
                <li>their worst-case optimal size and computation, and</li>
                <li>constant-delay enumeration of the represented tuples.</li>
              </ul>
            </div>
            <div class="text-center g-width-60x--md mx-auto g-my-40">
              <h3 class="text-uppercase g-color-primary">
                Where are Factorized Databases Used?
              </h3>
            </div>
            <div class="g-font-size-18 g-color-black-opacity-1_0 g-line-height-1_6 g-mb-30">
              <p>
                Factorized databases have impacted research in both database systems and database theory,
                in particular on:
              </p>
              <ul>
                <li><a href="#graph">representation and processing for graph data</a>,</li>
                <li><a href="#enumeration">enumeration for static and dynamic query evaluation</a>,</li>
                <li><a href="#provenance">query provenance management</a>,</li>
                <li><a href="#aggregates">factorized computation of aggregates</a> and</li>
                <li><a href="#learning">factorized machine learning</a>.</li>
              </ul>
              <p>
                For this reason, the ICDT 2012 paper <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:CONF/ICDT/OLTEANUZ12</citation>]</strong> on factorized databases received the <strong>ICDT
                  2022 Test of Time Award.</strong>
                This award <em><a href="https://databasetheory.org/ICDT/test-of-time">"recognizes a paper selected from
                    the proceedings of the ICDT 2012 conference that has had the highest impact in terms of research,
                    methodology, conceptual contribution, or transfer to practice over the past decade."</a></em>

              </p>
              <p>
                The rest of this note highlights a select number of research efforts that acknowledge the use of
                factorized database techniques in new settings or that extend the initial ICDT 2012 work. It gives
                citations from publications to emphasize the pivotal reliance on factorized databases. The timeliness of
                the influence of this work is remarkable, as a solid body of follow-up work has been published a decade
                after the initial work.
              </p>
            </div>
            <div class="text-center g-width-60x--md mx-auto g-my-40" id="graph">
              <h3 class="text-uppercase g-color-primary">
                Graph Representation and Processing
              </h3>
            </div>
            <div class="g-font-size-18 g-color-black-opacity-1_0 g-line-height-1_6 g-mb-30">
              <p>
                As argued in the system-building efforts that follow, factorization is a natural fit for the
                representation and processing of graph data. Graph traversals call for joins that have large outputs
                that are representable succinctly in factorized form.
              </p>
              <p>Salihoglu et al <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:journals/pvldb/GuptaMS21</citation>]</strong> revisit column-oriented storage and query
                processing techniques in the context of contemporary graph database management systems. A core decision
                in the design of such a system is to <strong>“adopt a factorized tuple set representation
                  scheme”</strong> to <strong>“avoid repetitions of values.”</strong> It developed a new block-based
                processor that <strong>“uses factorized representation of intermediate tuples.”</strong> Salihoglu and
                his team also study the problem of optimizing one-time and continuous subgraph queries using worst-case
                optimal join plans <strong class="g-color-primary">[<citation style="display:none;">10.1145/3446980
                  </citation>]</strong>. They put forward a cache that <strong>“gives benefits similar to
                  factorization”</strong>: whenever the matches of query vertices are independent, they can be done once
                for each match of further query vertices.
              </p>
              <p>
                Deutsch et al <strong class="g-color-primary">[<citation style="display:none;">10.1145/3448016.3457314
                  </citation>]</strong> present a scheme for parallel execution of SQL queries on top of a graph
                processing engine. This work uses an aggregation scheme <strong>“inspired by aggregation over hypertree
                  decompositions in factorized databases.”</strong> The values received by different vertices in the
                system <strong>“correspond to the factorized representation of the join result.”</strong>
              </p>
              <p>
                Wu et al <strong class="g-color-primary">[<citation style="display:none;">10.1007/978-3-030-27520-4_20
                  </citation>]</strong> address the challenge of quickly finding homomorphic matches for hybrid patterns
                over large data graphs, which is fundamental to graph analytics. They introduce the concept of an answer
                graph to encode all the possible homomorphisms from a pattern to the graph. This answer graph represents
                results succinctly <strong>“similar to factorized representations of query results studied in the
                  context of classical and probabilistic databases.”</strong> This property is useful, as in factorized
                databases, to <strong>“calculate the cardinality of the query answer [. . . ] without explicitly
                  enumerating the occurrences.”</strong>
              <p>
              <p>
                Godfrey et al <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:conf/edbt/Abul-BasherYGCC21</citation>]</strong> (best short paper award at EDBT 2021) propose
                an answer-graph method for the evaluation of SPARQL conjunctive queries. This approach <strong>“finds a
                  factorized answer set first, an answer graph, and then finds the embedding tuples from this.”</strong>
                They also point out that factorization can be effective for graph data: <strong>“While factorization is
                  sometimes a significant win for evaluating relational queries, it is virtually always a win for
                  evaluating graph CQs.”</strong>
              </p>
              <p>
                Vidal et al <strong class="g-color-primary">[<citation style="display:none;">10.1145/3102254.3102260
                  </citation>]</strong> present <strong>“a solution to the problem of factorizing RDF graphs describing
                  semantic sensor data.”</strong> A key contribution is an algorithm <strong>“that solves the problem of
                  query evaluation on a factorized RDF graph.”</strong> This work builds on <strong>“factorization
                  techniques [. . . ] for optimization of relational data and SQL query processing”</strong> and
                proposes <strong>“factorization technique tailored for semantically described sensor data.”</strong> The
                extended journal article <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:journals/jiis/KarimVA21</citation>]</strong> also investigates <strong>“the effectiveness of
                  the proposed factorization techniques [...] as well as the impact of factorizing semantic sensor data
                  on query processing using LinkedSensorData benchmark.”</strong>
              </p>
            </div>
            <div class="text-center g-width-60x--md mx-auto g-my-40" id="enumeration">
              <h3 class="text-uppercase g-color-primary">
                Enumeration for Static Query Evaluation
              </h3>
            </div>
            <div class="g-font-size-18 g-color-black-opacity-1_0 g-line-height-1_6 g-mb-30">
              <p>
                A key property of factorized representations is that they <em>allow tuple enumeration with constant
                  delay</em> (that is, the time needed to output the first tuple as well as the time from outputting one
                tuple to outputting the next is constant in the size of the representation). This gives a refinement of
                the computational complexity of a query that consists of two components:
              </p>
              <ol>
                <li>The preprocessing time, which is essentially the construction of the factorized representation of
                  the query result.</li>
                <li>The enumeration delay, which is the time between consecutive output tuples.</li>
              </ol>
              <p>
                The ICDT 2012 paper <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:CONF/ICDT/OLTEANUZ12</citation>]</strong> and its extended TODS version <strong
                  class="g-color-primary">[<citation style="display:none;">DBLP:journals/tods/OlteanuZ15</citation>
                  ]</strong> are the first to settle this refined complexity to <em>O(N<sup>fhtw(Q)</sup>)</em> for
                preprocessing time and <em>O(1)</em> for enumeration delay for any conjunctive query <em>Q</em>, where
                <em>N</em> is the size of the database and <em>fhtw</em> is the fractional hypertree width of
                <em>Q</em>. The acclaimed prior result by Bagan, Durand, and Grandjean <strong class="g-color-primary">[
                  <citation style="display:none;">DBLP:conf/csl/BaganDG07</citation>]
                </strong> guarantees linear
                preprocessing time and constant delay for free-connex acyclic conjunctive queries. A number of follow-up
                publications considered more expressive queries, restricted databases, preprocessing-enumeration
                trade-offs for both static and dynamic query evaluation. Some of these efforts that directly use the
                results on constant-delay enumeration in factorized databases are highlighted below.
              <p>
              <p>
                In a series of papers, Amarilli et al <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:conf/icalp/AmarilliBJM17</citation>]</strong> developed circuits that are more general than
                factorizations and still allow for constant-delay enumeration. Their work focuses on efficient
                enumeration algorithms, such as that for factorized representations of query results, with strict
                requirements: the preprocessing must be linear in the input size, and the delay between successive
                solutions must be constant. It also shows how the d-DNNF circuits <strong>“generalize the deterministic
                  factorized representations of relational instances.”</strong> It also <strong>“gives enumeration
                  algorithms with linear preprocessing and constant delay for arbitrary deterministic d-representations
                  [a form of factorized representation], extending the enumeration result [of factorized
                  databases].”</strong> The work also describes <strong>“links to factorized databases and strengthens
                  the enumeration result”</strong> in the original factorized database work. Amarilli and collaborators
                <strong class="g-color-primary">[<citation style="display:none;">DBLP:conf/icdt/AmarilliBM18</citation>
                  ]</strong> further consider the problem of enumeration on trees under relabelings. It defines
                set-valued circuits, which <strong>“can also be seen to be isomorphic to arithmetic circuits, and
                  generalize factorized representations.”</strong>
              </p>
              <p>
                Toru&nacute;czyk <strong class="g-color-primary">[<citation style="display:none;">
                    10.1145/3375395.3387660</citation>]</strong> proposes an algebraic framework for studying efficient
                algorithms for query evaluation, aggregation, enumeration, and maintenance under updates, on sparse
                databases. This work introduces circuits that <strong>“can be alternatively viewed as factorized
                  representations (extended by suitable permanent operators) of query answers.”</strong>
              </p>
              <p>
                Koutris et al <strong class="g-color-primary">[<citation style="display:none;">DBLP:conf/icdt/DeepHK21
                  </citation>]</strong> investigate the trade-off between preprocessing time and delay guarantees for
                the enumeration of star and path queries with projections. Their further work considers similar
                trade-offs between compressed representation and answer time for queries with access patterns <strong
                  class="g-color-primary">[<citation style="display:none;">10.1145/3196959.3196979</citation>]</strong>.
                They say: <strong>“The key observation is that we can take advantage of the underlying logical structure
                  in order to design algorithms that can compress the data effectively. This idea has been explored
                  before in the context of factorized databases, which can be viewed as a form of logical compression.
                  Our approach builds upon the idea of using query decompositions as a factorized representation, and we
                  show that for certain access patterns it is possible to go below <em>|D|<sup>fhw</sup></em> space for
                  constant delay enumeration.”</strong>
              </p>
              <p>
                Further work considers the <em>enumeration of query result following a given order</em>. Bakybayev et al
                <strong class="g-color-primary">[<citation style="display:none;">DBLP:journals/pvldb/BakibayevKOZ13
                  </citation>]</strong> revisits the enumeration on factorized databases and characterizes which
                factorization structures admit constant-delay enumeration for a given order-by clause. This is later
                generalized to complex enumeration orders used in ranked enumeration by Tziavelis et al <strong
                  class="g-color-primary">[<citation style="display:none;">10.14778/3397230.3397250</citation>]</strong>
                and Carmeli et al <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:conf/pods/CarmeliTGKR21</citation>]</strong>.
              </p>
              <p>
                Tziavelis et al <strong class="g-color-primary">[<citation style="display:none;">
                    10.14778/3397230.3397250</citation>]</strong> note that <strong>“factorized databases exploit the
                  distributivity of product over union to represent query results compactly and generalize the results
                  on bounded fhw to the non-Boolean case. Our encoding as a DP graph leverages the same principles and
                  is at least as efficient space-wise.”</strong>
              </p>
              <p>
                Carmeli et al <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:conf/pods/CarmeliTGKR21</citation>]</strong> conclude their paper with the statement that
                <strong>“we view this work as part of a bigger challenge that continues the line of research on
                  factorized representations in databases: how can we represent the output of a query in a way that,
                  compared to the explicit representation, is fundamentally more compact and efficiently computable, yet
                  equally useful to downstream operations?”</strong>. The non-<em>disruptive trio</em> characterization
                of queries that admit constant access time for tuples in their results corresponds to the alternative
                characterization for constant-delay enumeration from factorized representations over variable orders,
                put forward in <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:journals/pvldb/BakibayevKOZ13</citation>]</strong>: Constant-delay enumeration can be achieved
                for those factorized representations over variable orders where the order of the variables in the
                order-by clause is a prefix of a topological ordering of the variable order.
              </p>
            </div>
            <div class="text-center g-width-60x--md mx-auto g-my-40" id="enumeration">
              <h3 class="text-uppercase g-color-primary">
                Enumeration for Dynamic Query Evaluation
              </h3>
            </div>
            <div class="g-font-size-18 g-color-black-opacity-1_0 g-line-height-1_6 g-mb-30">
              <p>
                Beyond the static setting, factorized representations have been used for dynamic query evaluation, that
                is, for maintaining the results of queries under inserts to and deletes from the input database.
              </p>
              <p>
                Schweikardt et al <strong class="g-color-primary">[<citation style="display:none;">
                    10.1145/3034786.3034789</citation>]</strong> consider the task of enumerating and counting answers
                to conjunctive queries in the presence of tuple insertions and deletions. Essentially, <strong>“the
                  dynamic data structure that is computed by our algorithm can be viewed as an f-representation [a form
                  of factorized representation] of the query result, but not every f-representation can be efficiently
                  maintained under database updates.”</strong>
              </p>
              <p>
                Salihoglu et al <strong class="g-color-primary">[<citation style="display:none;">10.1145/3446980
                  </citation>]</strong> point out that the Dynamic Constant-delay Linear Representation (DCLR) data
                structure and the Dynamic Yannakakis Algorithm <strong class="g-color-primary">[<citation
                    style="display:none;">DBLP:conf/sigmod/IdrisUV17</citation>]</strong> are <strong>“reminiscent of
                  factorized database representation and processing.”</strong>
              </p>
              <p>
                F-IVM is an <a href="https://github.com/fdbresearch/FIVM">open-source prototype</a> that unifies
                maintenance for a variety of tasks, including gradient computation for learning linear regression models
                over joins, matrix chain multiplication, and factorized evaluation of conjunctive queries <strong
                  class="g-color-primary">[<citation style="display:none;">DBLP:conf/sigmod/NikolicO18</citation>
                  ]</strong>. It is <strong>“the first approach to employ factorized computation for three aspects of
                  incremental maintenance for queries with aggregates and joins: (1) it exploits insights from query
                  evaluation algorithms with best known complexity and optimizations that push aggregates past joins;
                  (2) it can process bulk updates expressed as low-rank decompositions; and (3) it can maintain
                  compressed representation of query results.”</strong>
              </p>
              <p>
                Kara et al <strong class="g-color-primary">[<citation style="display:none;">10.1145/3375395.3387646
                  </citation>]</strong> introduce a <a
                  href="https://fdbresearch.github.io/ivme.html">preprocessing-enumeration-update trade-off map</a> for
                the static and dynamic evaluation of hierarchical conjunctive queries. It recovers a large number of
                prior results, including the original result on factorized databases in the static setting. It uses
                F-IVM's factorized representations called view trees to represent partial evaluation and maintenance of
                the result of a given hierarchical query under light/heavy value degree constraints.
              </p>
            </div>
            <div class="text-center g-width-60x--md mx-auto g-my-40" id="provenance">
              <h3 class="text-uppercase g-color-primary">
                Fine-Grained Query Provenance
              </h3>
            </div>
            <div class="g-font-size-18 g-color-black-opacity-1_0 g-line-height-1_6 g-mb-30">
              <p>
                The ICDT 2012 paper <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:CONF/ICDT/OLTEANUZ12</citation>]</strong> also introduces effective techniques for the
                factorization of provenance polynomials of conjunctive queries. This has been used subsequently in a
                number of works, where the provenance information is too large to be stored and queried effectively.
              </p>
              <p>
                Glavic et al <strong class="g-color-primary">[<citation style="display:none;">DBLP:journals/vldb/LeeLG19
                  </citation>]</strong> introduce a practical system for why and why-not provenance called PUG
                (Provenance Unification through Graphs). PUG takes a provenance question and Datalog query as input and
                generates a Datalog program that computes an explanation, that is, the part of the provenance that is
                relevant to answer the question. It demonstrates <strong>“how a desirable factorization of provenance
                  can be achieved by rewriting an input query .. This is akin to factorization of provenance polynomials
                  in the semiring model and utilizes factorized databases techniques”.</strong> Section 9 of this work
                is devoted to provenance factorization and how to <strong>“extend our approach to produce concise,
                  factorized representations of provenance”.</strong>
              </p>
              <p>
                In work that received the VLDB 2017 best paper award <strong class="g-color-primary">[<citation
                    style="display:none;">DBLP:journals/pvldb/DeutchFG17</citation>]</strong> and follow-up journal
                articles <strong class="g-color-primary">[<citation style="display:none;">DBLP:journals/vldb/DeutchFG20
                  </citation>, <citation style="display:none;">10.1145/3277006.3277017</citation>]</strong>, Deutch and
                his team put forward a natural language (NL) interface for formulating database queries and an answering
                system that is based on the provenance of tuples in the query result, detailing not only the results but
                also their explanations. Since provenance is typically large, this work introduces <strong>“solutions
                  for its effective presentation as NL text: one that is based on provenance factorization, with novel
                  desiderata relevant to the NL case, and one that is based on summarization”.</strong> The core of
                their method is based on the observation underlying factorization: <strong>“As observed already in
                  previous work, different assignments (explanations) may have significant parts in common, and this can
                  be leveraged in a factorization that groups together multiple occurrences... Importantly, we impose a
                  novel constraint on the factorizations that we look for (which we call compatibility), intuitively
                  capturing that their structure is consistent with a partial order defined by the parse tree of the
                  question”.</strong> The solutions put forward rely on extensions of the original provenance
                factorization technique: <strong>“We propose two solutions: the first based on the idea of provenance
                  factorization, and the second leveraging factorization to provide a summarized form”.</strong>
              </p>
              <p>
                Ives et al <strong class="g-color-primary">[<citation style="display:none;">10.14778/3436905.3436909
                  </citation>]</strong> discuss solutions for storing fine-grained provenance in relational storage
                systems while both compressing and protecting it via cryptographic hashes. The motivation is to
                facilitate reproducible data science and auditable data analyses, by tracking the processes and inputs
                responsible for each result of an analysis. A key technical contribution is a provenance archival system
                that efficiently stores provenance for computations computed over time. This system
                <strong>“opportunistically exploits shared subexpressions as they occur”</strong>, which is acknowledged
                as a form of factorization. It also points out that Bao et al <strong class="g-color-primary">[<citation
                    style="display:none;">10.1145/2396761.2398439</citation>]</strong> developed strategies for
                factoring out provenance storage for common query expressions, following the original work on provenance
                factorization.
              </p>

            </div>

            <div class="text-center g-width-60x--md mx-auto g-my-40" id="aggregates">
              <h3 class="text-uppercase g-color-primary">
                Factorized Aggregate Computation
              </h3>
            </div>
            <div class="g-font-size-18 g-color-black-opacity-1_0 g-line-height-1_6 g-mb-30">
              <p>
                A distinct and rich line of work enabled by the ICDT 2012 paper is on efficient computation over
                factorized data. A first approach appeared in the VLDB 2013 paper by Bakibayev et al <strong
                  class="g-color-primary">[<citation style="display:none;">DBLP:journals/pvldb/BakibayevKOZ13</citation>
                  ]</strong>, where it is shown that the computation of group-by aggregates can benefit from factorized
                joins.
              </p>
              <p>
                The framework of Functional Aggregate Queries (FAQ) by Abo Khamis et al <strong
                  class="g-color-primary">[<citation style="display:none;">DBLP:conf/pods/KhamisNR16</citation>
                  ]</strong> (PODS’20 best paper award) and AJAR by R&eacute; et al <strong class="g-color-primary">[
                  <citation style="display:none;">10.1145/2902251.2902293</citation>]
                </strong> established the same
                computational complexity for answering conjunctive queries with aggregates as that of factorized
                aggregates by Bakibayev et al <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:journals/pvldb/BakibayevKOZ13</citation>]</strong> when computed over factorized
                representations for conjunctive queries <strong class="g-color-primary">[<citation
                    style="display:none;">DBLP:journals/tods/OlteanuZ15</citation>]</strong>. The FAQ paper notes about
                the relationship with prior work on factorized databases: <strong>“Bakibayev et al and Olteanu and
                  Z&aacute;vodn&yacute; introduced the notion of factorized databases, and showed how one can
                  efficiently compute join and aggregates over factorized databases. In hindsight there is much in
                  common between their approach and InsideOut applied to the single semiring case. Both approaches have
                  the same runtime complexity, because both are dynamic programming algorithms, InsideOut is bottom-up,
                  and factorized database computation is top-down (memoized).”</strong>
              <p>
              <p>
                The AJAR paper <strong class="g-color-primary">[<citation style="display:none;">10.1145/2902251.2902293
                  </citation>]</strong> also notes that <strong>“There is a standard modification to Yannakakis to
                  handle aggregations, but the classic analysis provides only a <em>O(IN · OUT)</em> bound. Bakibayev,
                  Kocisky, Olteanu, and Zavodny study aggregation-join queries in factorized databases, and later
                  Olteanu and Z&aacute;vodn&yacute; connected factorized databases and GHDs/GHDJoin [the TODS extended
                  version of the ICDT 2012 paper]. They develop the intuition that if output attributes are above
                  non-output attributes, the +OUT runtime is preserved; we use the same intuition to develop and analyze
                  AggroGHDJoin, a variant to GHDJoin for aggregate-join queries.”</strong> AJAR forms the basis of the
                EmptyHeaded system <strong class="g-color-primary">[<citation style="display:none;">10.1145/3129246
                  </citation>]</strong>, which adopts factorized aggregate computation: <strong>“Previous work has
                  investigated aggregations over hypertree decompositions [citations to factorized databases].
                  EmptyHeaded adopts this previous work in a straightforward way.”</strong>
              </p>
              <p>
                Wu et al <strong class="g-color-primary">[<citation style="display:none;">huang2021reptile</citation>
                  ]</strong> adopted the factorized computational paradigm for the design and implementation of a query
                explanation system called Reptile. This system <strong>“computes a succinct factorised matrix
                  representation that reduces the matrix representation by orders of magnitude”</strong> and
                <strong>“extend prior work, which developed model training procedures over factorised matrices derived
                  from join queries, to matrices based on join-aggregation queries that exhibit fewer
                  redundancies.”</strong> It <strong>“adapts factorized representations to compactly represent the
                  feature matrix, and extend matrix operations to support factorized representations.”</strong>
              </p>
              <p>
                Capelli et al <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:journals/corr/abs-1901-03633</citation>]</strong> have recently proposed an approach to compute
                complex dependency weighted aggregations over factorized databases. They <strong>“based [their] approach
                  on the framework of factorized databases of Olteanu and Z&aacute;vodn&yacute;”</strong>. The core of
                their computational approach is to factorize the linear program, whose optimal solution is the
                dependency weighted aggregation, following the structure of the underlying factorized data join:
                <strong>“To solve ground linear programs efficiently, we will work on factorized representations of
                  relations. We use a generalization of the framework of factorized databases introduced by Olteanu et
                  al”.</strong>
              </p>
            </div>
            <div class="text-center g-width-60x--md mx-auto g-my-40" id="learning">
              <h3 class="text-uppercase g-color-primary">
                Factorized Machine Learning
              </h3>
            </div>
            <div class="g-font-size-18 g-color-black-opacity-1_0 g-line-height-1_6 g-mb-30">
              <p>
                Realizing that model training in machine learning boils down to the evaluation of aggregates over joins,
                there followed a solid line of work on in-database factorized machine learning for a variety of models:
                linear regression <strong class="g-color-primary">[<citation style="display:none;">
                    10.1145/2882903.2882939</citation>]</strong>; polynomial regression, factorization machines, and
                principle component analysis <strong class="g-color-primary">[<citation style="display:none;">
                    10.1145/3375661</citation>]</strong>; support vector machines and arbitrary models trained using
                non-polynomial loss functions <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:journals/tods/KhamisCMNNOS20</citation>]</strong>; and k-means clustering <strong
                  class="g-color-primary">[<citation style="display:none;">DBLP:conf/aistats/CurtinM0NOS20</citation>
                  ]</strong>. This work led to several engines for factorized computation of batches of queries, the
                latest one is the <a href="https://github.com/fdbresearch/LMFAO">open-source LMFAO system</a> <strong
                  class="g-color-primary">[<citation style="display:none;">DBLP:conf/sigmod/SchleichOK0N19</citation>
                  ]</strong>.
              <p>
              <p>
                Inspired by this line of work on factorized databases, Kumar coined the terms <strong>“factorized
                  learning”</strong> <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:journals/pvldb/JustoYSPK21</citation>, <citation style="display:none;">
                    DBLP:conf/sigmod/KumarNP15</citation>]</strong> and <strong>“factorized linear algebra”</strong>
                <strong class="g-color-primary">[<citation style="display:none;">DBLP:journals/pvldb/ChenKNP17
                  </citation>, <citation style="display:none;">DBLP:conf/sigmod/LiC019</citation>]</strong> to emphasize
                the core aspect of computing aggregates over joins without materializing the joins explicitly:
                <strong>“We call our technique factorized learning, borrowing the terminology from “factorized”
                  databases [. . . ] We extend the general idea of factorized computation to ML algorithms over
                  joins”</strong> <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:conf/sigmod/KumarNP15</citation>]</strong>; <strong>“Is it possible to generalize the idea of
                  factorized ML and automate its application to a much wider variety of ML algorithms and platforms in a
                  unified manner?”</strong> <strong class="g-color-primary">[<citation style="display:none;">
                    DBLP:journals/pvldb/ChenKNP17</citation>]</strong>. In recent years, factorized machine learning has
                become an accepted approach beyond the works co-auhtored by Kumar and Olteanu, with examples such as the
                factorized support vector machines <strong class="g-color-primary">[<citation style="display:none;">
                    9101671</citation>]</strong>.
              </p>
            </div>

            <!-- <hr class="g-brd-gray-light-v4"> -->
          </article>
        </div>
        <!-- End Articles Content -->
      </div>
      <!-- Publications section -->
      <div class="row">
        <div class="col-lg-1 g-mb-80"></div>
        <div class="col-lg-10 g-mb-50 g-mb-0--lg">
          <div class="g-mb-30">
            <div class="u-heading-v3-1 g-mb-30">
              <h2 class="h5 u-heading-v3__title g-color-gray-dark-v1 text-uppercase g-brd-primary" id="references">
                References
              </h2>
            </div>
          </div>
          <ol>
            <div id="bibtex_display"></div>
          </ol>

          <div id="stickyblock-end">
          </div>
        </div>
      </div>
    </div>
  </main>
  <div class="bibtex_template">
    <li class="g-mb-15">
      <strong>
        <a class="url"><span class="title"></span></a>.
      </strong>
      <br>
      <span class="if author">
        <span class="author"></span>
      </span>
      <br>

      <span class="if journal">
        In <span class="journal" style="font-style: italic;"></span>.
      </span>
      <span class="if booktitle">
        In <span class="booktitle" style="font-style: italic;"></span>.
      </span>
      <span class="if mastersthesis">
        <span class="mastersthesis" style="font-style: italic;"></span>, Masters thesis.
      </span>
      <span class="if school">
        <i>Masters thesis,</i>&nbsp<span class="school"></span>.
      </span>
      <span class="if volume" style="font-style: italic;">
        <span class="volume"></span>
        <span class="if number" style="font-style: italic;">(<span class="number"></span>)</span>,&nbsp
        <span class="if pages">
          <span class="pages"></span>.&nbsp
        </span>
      </span>
      <span class="if edition">
        <span class="edition"></span> ed.,
      </span>
      <span class="if publisher">
        <span class="publisher"></span>.
      </span>
      <span class="if year">
        <span class="year"></span>.&nbsp
      </span>
    </li>
  </div>
  <textarea id="bibtex_input" style="display:none;">
    @inproceedings{DBLP:conf/icdt/OlteanuZ12,
      author    = {Dan Olteanu and
                   Jakub Z{\'{a}}vodn{\'{y}}},
      editor    = {Alin Deutsch},
      title     = {Factorised representations of query results: size bounds and readability},
      booktitle = {15th International Conference on Database Theory, {ICDT} '12, Berlin,
                   Germany, March 26-29, 2012},
      pages     = {285--298},
      publisher = {{ACM}},
      year      = {2012},
      url       = {https://doi.org/10.1145/2274576.2274607},
      doi       = {10.1145/2274576.2274607},
      timestamp = {Tue, 06 Nov 2018 16:59:26 +0100},
      biburl    = {https://dblp.org/rec/conf/icdt/OlteanuZ12.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    ### RELEVANT PAPERS CITING THE ICDT 2012 work
    
    
    @article{DBLP:journals/sigmod/OlteanuS16,
      author    = {Dan Olteanu and
                   Maximilian Schleich},
      title     = {Factorized Databases},
      journal   = {{SIGMOD} Rec.},
      volume    = {45},
      number    = {2},
      pages     = {5--16},
      year      = {2016},
      url       = {https://doi.org/10.1145/3003665.3003667},
      doi       = {10.1145/3003665.3003667},
      timestamp = {Fri, 06 Mar 2020 21:56:19 +0100},
      biburl    = {https://dblp.org/rec/journals/sigmod/OlteanuS16.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    
    ##################################################
    ##################################################
    ##################################################
    ##################################################
    
    @article{DBLP:journals/tods/OlteanuZ15,
      author    = {Dan Olteanu and
                   Jakub Z{\'{a}}vodn{\'{y}}},
      title     = {Size Bounds for Factorised Representations of Query Results},
      journal   = {{ACM} Trans. Database Syst.},
      volume    = {40},
      number    = {1},
      pages     = {2:1--2:44},
      year      = {2015},
      url       = {https://doi.org/10.1145/2656335},
      doi       = {10.1145/2656335},
      timestamp = {Tue, 06 Nov 2018 12:51:47 +0100},
      biburl    = {https://dblp.org/rec/journals/tods/OlteanuZ15.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
     
    ### RELEVANT PAPERS CITING THE TODS 2015 work
    
    ################################################
    #### ENUMERATION ####
    ################################################
    
    
    @inproceedings{DBLP:conf/csl/BaganDG07,
      author    = {Guillaume Bagan and
                   Arnaud Durand and
                   Etienne Grandjean},
      editor    = {Jacques Duparc and
                   Thomas A. Henzinger},
      title     = {On Acyclic Conjunctive Queries and Constant Delay Enumeration},
      booktitle = {Computer Science Logic, 21st International Workshop, {CSL} 2007, 16th
                   Annual Conference of the EACSL, Lausanne, Switzerland, September 11-15,
                   2007, Proceedings},
      series    = {Lecture Notes in Computer Science},
      volume    = {4646},
      pages     = {208--222},
      publisher = {Springer},
      year      = {2007},
      url       = {https://doi.org/10.1007/978-3-540-74915-8\_18},
      doi       = {10.1007/978-3-540-74915-8\_18},
      timestamp = {Tue, 14 May 2019 10:00:42 +0200},
      biburl    = {https://dblp.org/rec/conf/csl/BaganDG07.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    @misc{deep2021enumeration,
          title={Enumeration Algorithms for Conjunctive Queries with Projection}, 
          author={Shaleen Deep and Xiao Hu and Paraschos Koutris},
          year={2021},
          eprint={2101.03712},
          archivePrefix={arXiv},
          primaryClass={cs.DB},
          OPTnote = {star and path queries; directly inflluenced by IVMe; tradeoff between preprocessing time and delay guarantees for enumeration of path queries that contain projections.}
    }
    
    @inproceedings{DBLP:conf/icdt/DeepHK21,
      author    = {Shaleen Deep and
                   Xiao Hu and
                   Paraschos Koutris},
      editor    = {Ke Yi and
                   Zhewei Wei},
      title     = {Enumeration Algorithms for Conjunctive Queries with Projection},
      booktitle = {24th International Conference on Database Theory, {ICDT} 2021, March
                   23-26, 2021, Nicosia, Cyprus},
      series    = {LIPIcs},
      volume    = {186},
      pages     = {14:1--14:17},
      publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
      year      = {2021},
      url       = {https://doi.org/10.4230/LIPIcs.ICDT.2021.14},
      doi       = {10.4230/LIPIcs.ICDT.2021.14},
      timestamp = {Thu, 11 Mar 2021 17:44:44 +0100},
      biburl    = {https://dblp.org/rec/conf/icdt/DeepHK21.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    @inproceedings{10.1145/3196959.3196979,
    author = {Deep, Shaleen and Koutris, Paraschos},
    title = {Compressed Representations of Conjunctive Query Results},
    year = {2018},
    isbn = {9781450347068},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3196959.3196979},
    doi = {10.1145/3196959.3196979},
    abstract = {Relational queries, and in particular join queries, often generate large output results
    when executed over a huge dataset. In such cases, it is often infeasible to store
    the whole materialized output if we plan to reuse it further down a data processing
    pipeline. Motivated by this problem, we study the construction of space-efficient
    compressed representations of the output of conjunctive queries, with the goal of
    supporting the efficient access of the intermediate compressed result for a given
    access pattern. In particular, we initiate the study of an important tradeoff: minimizing
    the space necessary to store the compressed result, versus minimizing the answer time
    and delay for an access request over the result. Our main contribution is a novel
    parameterized data structure, which can be tuned to trade off space for answer time.
    The tradeoff allows us to control the space requirement of the data structure precisely,
    and depends both on the structure of the query and the access pattern. We show how
    we can use the data structure in conjunction with query decomposition techniques in
    order to efficiently represent the outputs for several classes of conjunctive queries.},
    booktitle = {Proceedings of the 37th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
    pages = {307–322},
    numpages = {16},
    keywords = {space delay tradeoff, query enumeration, compressed representation, constant delay enumeration, join algorithms},
    location = {Houston, TX, USA},
    series = {SIGMOD/PODS '18},
    OPTnote = {
    The idea of efficiently compressing query results has recently gained considerable attention, both in the context of factorized databases [22], as well as constant-delay enumeration [5, 26]. In these settings, the focus is to construct compressed representa- tions that allow for enumeration of the full result with constant delay... 
    In this work, we show that we can dramatically decrease the space for the compressed representation by both (i) taking advan- tage of the access pattern, and (ii) tolerating a possibly increased delay... Given such indexes, we can perform a full enumeration in constant delay starting from the root (which will be the empty bag), and visiting the nodes of the tree T in a pre-order fashion by following the indexes at each bag. This con- struction uses the same idea as d-representations [22], and requires spaceO(|D|fhw(H))... The key observation is that we can take advantage of the underlying logical structure in order to design algorithms that can compress the data effectively. This idea has been explored before in the context of factorized databases [22], which can be viewed as a form of logical compression. Our approach builds upon the idea of using query decompositions as a factorized representation, and we show that for certain access patterns it is possible to go below |D|fhw space for constant delay enumeration. }
    }
    
    @inproceedings{DBLP:conf/pods/CarmeliTGKR21,
      author    = {Nofar Carmeli and
                   Nikolaos Tziavelis and
                   Wolfgang Gatterbauer and
                   Benny Kimelfeld and
                   Mirek Riedewald},
      editor    = {Leonid Libkin and
                   Reinhard Pichler and
                   Paolo Guagliardo},
      title     = {Tractable Orders for Direct Access to Ranked Answers of Conjunctive
                   Queries},
      booktitle = {PODS'21: Proceedings of the 40th {ACM} {SIGMOD-SIGACT-SIGAI} Symposium
                   on Principles of Database Systems, Virtual Event, China, June 20-25,
                   2021},
      pages     = {325--341},
      publisher = {{ACM}},
      year      = {2021},
      url       = {https://doi.org/10.1145/3452021.3458331},
      doi       = {10.1145/3452021.3458331},
      timestamp = {Mon, 21 Jun 2021 12:19:38 +0200},
      biburl    = {https://dblp.org/rec/conf/pods/CarmeliTGKR21.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    @article{DBLP:journals/corr/abs-2109-10889,
      author    = {Shaleen Deep and
                   Xiao Hu and
                   Paraschos Koutris},
      title     = {Space-Time Tradeoffs for Answering Boolean Conjunctive Queries},
      journal   = {CoRR},
      volume    = {abs/2109.10889},
      year      = {2021},
      url       = {https://arxiv.org/abs/2109.10889},
      eprinttype = {arXiv},
      eprint    = {2109.10889},
      timestamp = {Mon, 27 Sep 2021 15:21:05 +0200},
      biburl    = {https://dblp.org/rec/journals/corr/abs-2109-10889.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    @inproceedings{10.1145/3375395.3387646,
    author = {Kara, Ahmet and Nikolic, Milos and Olteanu, Dan and Zhang, Haozhe},
    title = {Trade-Offs in Static and Dynamic Evaluation of Hierarchical Queries},
    year = {2020},
    isbn = {9781450371087},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3375395.3387646},
    doi = {10.1145/3375395.3387646},
    abstract = {We investigate trade-offs in static and dynamic evaluation of hierarchical queries
    with arbitrary free variables. In the static setting, the trade-off is between the
    time to partially compute the query result and the delay needed to enumerate its tuples.
    In the dynamic setting, we additionally consider the time needed to update the query
    result under single-tuple inserts or deletes to the database.Our approach observes
    the degree of values in the database and uses different computation and maintenance
    strategies for high-degree (heavy) and low-degree (light) values. For the latter it
    partially computes the result, while for the former it computes enough information
    to allow for on-the-fly enumeration.The main result of this work defines the preprocessing
    time, the update time, and the enumeration delay as functions of the light/heavy threshold.
    By conveniently choosing this threshold, our approach recovers a number of prior results
    when restricted to hierarchical queries.For a restricted class of hierarchical queries,
    our approach can achieve worst-case optimal update time and enumeration delay conditioned
    on the Online Matrix-Vector Multiplication Conjecture.},
    booktitle = {Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
    pages = {375–392},
    numpages = {18},
    keywords = {sublinear enumeration delay, adaptive query evaluation, sublinear update time, hierarchical queries, incremental view maintenance},
    location = {Portland, OR, USA},
    series = {PODS'20},
    OPTnote = {preprocessing follows factorised computation; case for heavy values builds a factorised representation to ensure the right delay.},
    }
    
    
    @article{10.14778/3397230.3397250,
    author = {Tziavelis, Nikolaos and Ajwani, Deepak and Gatterbauer, Wolfgang and Riedewald, Mirek and Yang, Xiaofeng},
    title = {Optimal Algorithms for Ranked Enumeration of Answers to Full Conjunctive Queries},
    year = {2020},
    issue_date = {May 2020},
    publisher = {VLDB Endowment},
    volume = {13},
    number = {9},
    issn = {2150-8097},
    url = {https://doi.org/10.14778/3397230.3397250},
    doi = {10.14778/3397230.3397250},
    abstract = {We study ranked enumeration of join-query results according to very general orders
    defined by selective dioids. Our main contribution is a framework for ranked enumeration
    over a class of dynamic programming problems that generalizes seemingly different
    problems that had been studied in isolation. To this end, we extend classic algorithms
    that find the k-shortest paths in a weighted graph. For full conjunctive queries,
    including cyclic ones, our approach is optimal in terms of the time to return the
    top result and the delay between results. These optimality properties are derived
    for the widely used notion of data complexity, which treats query size as a constant.
    By performing a careful cost analysis, we are able to uncover a previously unknown
    tradeoff between two incomparable enumeration approaches: one has lower complexity
    when the number of returned results is small, the other when the number is very large.
    We theoretically and empirically demonstrate the superiority of our techniques over
    batch algorithms, which produce the full result and then sort it. Our technique is
    not only faster for returning the first few results, but on some inputs beats the
    batch algorithm even when all results are produced.},
    journal = {Proc. VLDB Endow.},
    month = {may},
    pages = {1582–1597},
    numpages = {16},
    OPTnote = {Factorized databases [13, 75, 76, 82] exploit the distributivity of product over union to represent query results compactly and generalize the results on bounded fhw to the non-Boolean case [77]. Our encoding as a DP graph leverages the same principles and is at least as efficient space-wise... }
    }
    
    @inproceedings{10.1145/3034786.3034789,
    author = {Berkholz, Christoph and Keppeler, Jens and Schweikardt, Nicole},
    title = {Answering Conjunctive Queries under Updates},
    year = {2017},
    isbn = {9781450341981},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3034786.3034789},
    doi = {10.1145/3034786.3034789},
    abstract = {We consider the task of enumerating and counting answers to k-ary conjunctive queries
    against relational databases that may be updated by inserting or deleting tuples.
    We exhibit a new notion of q-hierarchical conjunctive queries and show that these
    can be maintained efficiently in the following sense. During a linear time pre-processing
    phase, we can build a data structure that enables constant delay enumeration of the
    query results; and when the database is updated, we can update the data structure
    and restart the enumeration phase within constant time. For the special case of self-join
    free conjunctive queries we obtain a dichotomy: if a query is not q-hierarchical,
    then query enumeration with sublinear *) delay and sublinear update time (and arbitrary
    preprocessing time) is impossible.For answering Boolean conjunctive queries and for
    the more general problem of counting the number of solutions of k-ary queries we obtain
    complete dichotomies: if the query's homomorphic core is q-hierarchical, then size
    of the the query result can be computed in linear time and maintained with constant
    update time. Otherwise, the size of the query result cannot be maintained with sublinear
    update time.All our lower bounds rely on the OMv-conjecture, a conjecture on the hardness
    of online matrix-vector multiplication that has recently emerged in the field of fine-grained
    complexity to characterise the hardness of dynamic problems. The lower bound for the
    counting problem additionally relies on the orthogonal vectors conjecture, which in
    turn is implied by the strong exponential time hypothesis.*) By sublinear we mean
    O(n(1-ε) for some ε > 0, where n is the size of the active domain of the current database.},
    booktitle = {Proceedings of the 36th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
    pages = {303–318},
    numpages = {16},
    keywords = {dynamic algorithms, constant delay enumeration, online matrix-vector multiplication, dichotomy, counting complexity, query evaluation},
    location = {Chicago, Illinois, USA},
    series = {PODS '17},
    OPTnote = {The dynamic data structure that is computed by our algorithm can be viewed as an f-representation of the query result [31], but not every f-representation can be efficiently maintained under database updates... }
    }
    
    
    
    
    @inproceedings{DBLP:conf/icalp/AmarilliBJM17,
      author    = {Antoine Amarilli and
                   Pierre Bourhis and
                   Louis Jachiet and
                   Stefan Mengel},
      editor    = {Ioannis Chatzigiannakis and
                   Piotr Indyk and
                   Fabian Kuhn and
                   Anca Muscholl},
      title     = {A Circuit-Based Approach to Efficient Enumeration},
      booktitle = {44th International Colloquium on Automata, Languages, and Programming,
                   {ICALP} 2017, July 10-14, 2017, Warsaw, Poland},
      series    = {LIPIcs},
      volume    = {80},
      pages     = {111:1--111:15},
      publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
      year      = {2017},
      url       = {https://doi.org/10.4230/LIPIcs.ICALP.2017.111},
      doi       = {10.4230/LIPIcs.ICALP.2017.111},
      timestamp = {Tue, 11 Feb 2020 15:52:14 +0100},
      biburl    = {https://dblp.org/rec/conf/icalp/AmarilliBJM17.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org},
    OPTnote = {
    We focus on a well-studied class of efficient enumeration algorithms with very strict requirements: the preprocessing must be linear in the input size, and the delay between successive solutions must be constant. Such algorithms have been studied in particular for database applications, to enumerate query answers (see [18, 5, 19, 6, 7, 23, 24] and the recent survey [32]), or to enumerate the tuples of factorized database representations [28]...  Second, we show how d-DNNFs generalize the deterministic factorized representations of relational instances studied in database theory [28]. This allows us to give enumeration algorithms with linear preprocessing and constant delay for arbitrary deterministic d-representations, extending the enumeration result of [28]... The second application describes links to factorized databases and strengthens the enumeration result of [28].
    }
    }
    
    
    @inproceedings{DBLP:conf/icdt/AmarilliBM18,
      author    = {Antoine Amarilli and
                   Pierre Bourhis and
                   Stefan Mengel},
      editor    = {Benny Kimelfeld and
                   Yael Amsterdamer},
      title     = {Enumeration on Trees under Relabelings},
      booktitle = {21st International Conference on Database Theory, {ICDT} 2018, March
                   26-29, 2018, Vienna, Austria},
      series    = {LIPIcs},
      volume    = {98},
      pages     = {5:1--5:18},
      publisher = {Schloss Dagstuhl - Leibniz-Zentrum f{\"{u}}r Informatik},
      year      = {2018},
      url       = {https://doi.org/10.4230/LIPIcs.ICDT.2018.5},
      doi       = {10.4230/LIPIcs.ICDT.2018.5},
      timestamp = {Tue, 11 Feb 2020 15:52:14 +0100},
      biburl    = {https://dblp.org/rec/conf/icdt/AmarilliBM18.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org},
      OPTnote = { We define set-valued circuits, which are an equivalent rephrasing of the circuits in zero- suppressed semantics used in [3]. They can also be seen to be isomorphic to arithmetic circuits, and generalize factorized representations used in database theory [27].
    },
      abstract = {We study how to evaluate MSO queries with free variables on trees, within the framework of enumeration algorithms. Previous work has shown how to enumerate answers with linear-time preprocessing and delay linear in the size of each output, i.e., constant-delay for free first-order variables. We extend this result to support relabelings, a restricted kind of update operations on trees which allows us to change the node labels. Our main result shows that we can enumerate the answers of MSO queries on trees with linear-time preprocessing and delay linear in each answer, while supporting node relabelings in logarithmic time. To prove this, we reuse the circuit-based enumeration structure from our earlier work, and develop techniques to maintain its index under node relabelings. We also show how enumeration under relabelings can be applied to evaluate practical query languages, such as aggregate, group-by, and parameterized queries.}
    }
    
    @inproceedings{10.1145/3375395.3387660,
    author = {Toru\'{n}czyk, Szymon},
    title = {Aggregate Queries on Sparse Databases},
    year = {2020},
    isbn = {9781450371087},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3375395.3387660},
    doi = {10.1145/3375395.3387660},
    abstract = {We propose an algebraic framework for studying efficient algorithms for query evaluation,
    aggregation, enumeration, and maintenance under updates, on sparse databases. Our
    framework allows to treat those problems in a unified way, by considering various
    semirings, depending on the considered problem. As a concrete application, we propose
    a powerful query language extending first-order logic by aggregation in multiple semirings.
    We obtain an optimal algorithm for computing the answers of such queries on sparse
    databases. More precisely, given a database from a fixed class with bounded expansion,
    the algorithm computes in linear timea data structure which allows to enumerate the
    set of answers to the query, with constant delay between two outputs.},
    booktitle = {Proceedings of the 39th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
    pages = {427–443},
    numpages = {17},
    keywords = {query evaluation, semiring circuits, bounded expansion, updates, provenance, sparse graphs, enumeration},
    location = {Portland, OR, USA},
    series = {PODS'20},
    OPTnote = {Our circuits are very similar to deterministic decomposable nega- tion normal forms (d-DNNF) used in knowledge compilation [5], and generalize them by allowing permanent gates, which, in the circuits obtained from our construction, are both disjunctive and decomposable, in an appropriate sense. Our circuits can be alter- natively viewed as factorized representations (extended by suitable permanent operators) of query answers [20].}
    }
    
    @inproceedings{DBLP:conf/sigmod/IdrisUV17,
      author    = {Muhammad Idris and
                   Mart{\'{\i}}n Ugarte and
                   Stijn Vansummeren},
      editor    = {Semih Salihoglu and
                   Wenchao Zhou and
                   Rada Chirkova and
                   Jun Yang and
                   Dan Suciu},
      title     = {The Dynamic Yannakakis Algorithm: Compact and Efficient Query Processing
                   Under Updates},
      booktitle = {Proceedings of the 2017 {ACM} International Conference on Management
                   of Data, {SIGMOD} Conference 2017, Chicago, IL, USA, May 14-19, 2017},
      pages     = {1259--1274},
      publisher = {{ACM}},
      year      = {2017},
      url       = {https://doi.org/10.1145/3035918.3064027},
      doi       = {10.1145/3035918.3064027},
      timestamp = {Tue, 06 Nov 2018 11:07:39 +0100},
      biburl    = {https://dblp.org/rec/conf/sigmod/IdrisUV17.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    @article{DBLP:journals/pvldb/BakibayevKOZ13,
      author    = {Nurzhan Bakibayev and
                   Tom{\'{a}}s Kocisk{\'{y}} and
                   Dan Olteanu and
                   Jakub Zavodny},
      title     = {Aggregation and Ordering in Factorised Databases},
      journal   = {Proc. {VLDB} Endow.},
      volume    = {6},
      number    = {14},
      pages     = {1990--2001},
      year      = {2013},
      url       = {http://www.vldb.org/pvldb/vol6/p1990-zavodny.pdf},
      doi       = {10.14778/2556549.2556579},
      timestamp = {Sat, 25 Apr 2020 13:58:34 +0200},
      biburl    = {https://dblp.org/rec/journals/pvldb/BakibayevKOZ13.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    @inproceedings{DBLP:conf/sigmod/NikolicO18,
      author    = {Milos Nikolic and
                   Dan Olteanu},
      editor    = {Gautam Das and
                   Christopher M. Jermaine and
                   Philip A. Bernstein},
      title     = {Incremental View Maintenance with Triple Lock Factorization Benefits},
      booktitle = {Proceedings of the 2018 International Conference on Management of
                   Data, {SIGMOD} Conference 2018, Houston, TX, USA, June 10-15, 2018},
      pages     = {365--380},
      publisher = {{ACM}},
      year      = {2018},
      url       = {https://doi.org/10.1145/3183713.3183758},
      doi       = {10.1145/3183713.3183758},
      timestamp = {Wed, 21 Nov 2018 12:44:08 +0100},
      biburl    = {https://dblp.org/rec/conf/sigmod/NikolicO18.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    
    ##################
    #### GRAPH DB ####
    ##################
    
    
    @article{DBLP:journals/pvldb/GuptaMS21,
      author    = {Pranjal Gupta and
                   Amine Mhedhbi and
                   Semih Salihoglu},
      title     = {Columnar Storage and List-based Processing for Graph Database Management
                   Systems},
      journal   = {Proc. {VLDB} Endow.},
      volume    = {14},
      number    = {11},
      pages     = {2491--2504},
      year      = {2021},
      url       = {http://www.vldb.org/pvldb/vol14/p2491-gupta.pdf},
      timestamp = {Fri, 27 Aug 2021 17:02:27 +0200},
      biburl    = {https://dblp.org/rec/journals/pvldb/GuptaMS21.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org},
      OPTnote = {Therefore to represent the tuples that are produced by n-n joins, repetitions of values are necessary. To address these repetitions we adopt a factorized tuple set representation scheme [52]. We developed a new block-based processor called list-based pro- cessor (LBP), which we next describe. LBP uses factorized represen- tation of intermediate tuples [8, 51, 52] to address the data copying problem and uses block sizes set to the lengths of adjacency lists in the database, to exploit list-based data storage in GDBMSs.}
    }
    
    @inproceedings{10.1145/3448016.3457314,
    author = {Smagulova, Ainur and Deutsch, Alin},
    title = {Vertex-Centric Parallel Computation of SQL Queries},
    year = {2021},
    isbn = {9781450383431},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3448016.3457314},
    doi = {10.1145/3448016.3457314},
    abstract = {We present a scheme for parallel execution of SQL queries on top of any vertex-centric
    BSP graph processing engine. The scheme comprises a graph encoding of relational instances
    and a vertex program specification of our algorithm called TAG-join, which matches
    the theoretical communication and computation complexity of state-of-the-art join
    algorithms. When run on top of the vertex-centric TigerGraph database engine on a
    single multi-core server, TAG-join exploits thread parallelism and is competitive
    with (and often outperforms) reference RDBMSs on the TPC benchmarks they are traditionally
    tuned for. In a distributed cluster, TAG-join outperforms the popular Spark SQL engine.},
    booktitle = {Proceedings of the 2021 International Conference on Management of Data},
    pages = {1664–1677},
    numpages = {14},
    keywords = {BSP parallel SQL evaluation, vertex-centric graph processing},
    location = {Virtual Event, China},
    series = {SIGMOD/PODS '21},
    OPTnote = {The aggregation scheme is inspired by aggregation over hypertree decompositions in factorized databases [14, 44], since our TAG plan is based on a GHD (recall §5.1)... In Superstep (3), the 𝐴-attribute and 𝐶-attribute values received at a 𝐵-attribute vertex correspond to the factorized representation of the join result [44], i.e. the latter can be obtained losslessly as their Cartesian product. If the distributed and factorized representation of the join is required, then Superstep (3) is skipped. }
    }
    
    @article{10.1145/3446980,
    author = {Mhedhbi, Amine and Kankanamge, Chathura and Salihoglu, Semih},
    title = {Optimizing One-Time and Continuous Subgraph Queries Using Worst-Case Optimal Joins},
    year = {2021},
    issue_date = {June 2021},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {46},
    number = {2},
    issn = {0362-5915},
    url = {https://doi.org/10.1145/3446980},
    doi = {10.1145/3446980},
    abstract = {We study the problem of optimizing one-time and continuous subgraph queries using
    the new worst-case optimal join plans. Worst-case optimal plans evaluate queries by
    matching one query vertex at a time using multiway intersections. The core problem
    in optimizing worst-case optimal plans is to pick an ordering of the query vertices
    to match. We make two main contributions:1. A cost-based dynamic programming optimizer
    for one-time queries that (i) picks efficient query vertex orderings for worst-case
    optimal plans and (ii) generates hybrid plans that mix traditional binary joins with
    worst-case optimal style multiway intersections. In addition to our optimizer, we
    describe an adaptive technique that changes the query vertex orderings of the worst-case
    optimal subplans during query execution for more efficient query evaluation. The plan
    space of our one-time optimizer contains plans that are not in the plan spaces based
    on tree decompositions from prior work.2. A cost-based greedy optimizer for continuous
    queries that builds on the delta subgraph query framework. Given a set of continuous
    queries, our optimizer decomposes these queries into multiple delta subgraph queries,
    picks a plan for each delta query, and generates a single combined plan that evaluates
    all of the queries. Our combined plans share computations across operators of the
    plans for the delta queries if the operators perform the same intersections. To increase
    the amount of computation shared, we describe an additional optimization that shares
    partial intersections across operators.Our optimizers use a new cost metric for worst-case
    optimal plans called intersection-cost. When generating hybrid plans, our dynamic
    programming optimizer for one-time queries combines intersection-cost with the cost
    of binary joins. We demonstrate the effectiveness of our plans, adaptive technique,
    and partial intersection sharing optimization through extensive experiments. Our optimizers
    are integrated into GraphflowDB.},
    journal = {ACM Trans. Database Syst.},
    month = {may},
    articleno = {6},
    numpages = {45},
    keywords = {Subgraph queries, worst-case optimal joins, generic join},
    OPTnote = {Our cache gives benefits similar to factorization [52]. In factorized processing, the results of a query are represented as Cartesian products of independent components of the query. In this case, matches of a1 and a4 are independent and can be done once for each match of a2a3. A study of factorized processing is an interesting topic for future work... Reference [27] introduces an algorithm to maintain results of acyclic queries under updates relying instead of materialization on a data structure called Dy- namic Constant-delay Linear Representation (DCLR). DCLR and the Dynamic Yannakakis Algorithm introduced guarantee linear time maintenance under updates while using only linear space in the size of the database. The technique is reminiscent of factorized database representa- tion and processing [52]... Finally, existing literature on subgraph matching, both in the one-time and continuous settings, contain several optimizations for identifying and evaluating independent components of a query separately. Example optimizations include factorization [52] or postponing the Cartesian product optimization from Reference [10].}
    }
    
    @inproceedings{10.1145/2882903.2915236,
    author = {Bi, Fei and Chang, Lijun and Lin, Xuemin and Qin, Lu and Zhang, Wenjie},
    title = {Efficient Subgraph Matching by Postponing Cartesian Products},
    year = {2016},
    isbn = {9781450335317},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2882903.2915236},
    doi = {10.1145/2882903.2915236},
    abstract = {In this paper, we study the problem of subgraph matching that extracts all subgraph
    isomorphic embeddings of a query graph q in a large data graph G. The existing algorithms
    for subgraph matching follow Ullmann's backtracking approach; that is, iteratively
    map query vertices to data vertices by following a matching order of query vertices.
    It has been shown that the matching order of query vertices is a very important aspect
    to the efficiency of a subgraph matching algorithm. Recently, many advanced techniques,
    such as enforcing connectivity and merging similar vertices in query or data graphs,
    have been proposed to provide an effective matching order with the aim to reduce unpromising
    intermediate results especially the ones caused by redundant Cartesian products. In
    this paper, for the first time we address the issue of unpromising results by Cartesian
    products from "dissimilar" vertices. We propose a new framework by postponing the
    Cartesian products based on the structure of a query to minimize the redundant Cartesian
    products. Our second contribution is proposing a new path-based auxiliary data structure,
    with the size O(|E(G)| x |V(q)|), to generate a matching order and conduct subgraph
    matching, which significantly reduces the exponential size O(|V(G)||V(q)|-1) of the
    existing path-based auxiliary data structure, where V (G) and E (G) are the vertex
    and edge sets of a data graph G, respectively, and V (q) is the vertex set of a query
    $q$. Extensive empirical studies on real and synthetic graphs demonstrate that our
    techniques outperform the state-of-the-art algorithms by up to $3$ orders of magnitude.},
    booktitle = {Proceedings of the 2016 International Conference on Management of Data},
    pages = {1199–1214},
    numpages = {16},
    keywords = {core-forest-leaf decomposition, postpone cartesian products, subgraph isomorphism, compact path index},
    location = {San Francisco, California, USA},
    series = {SIGMOD '16},
    OPTnote = {does not acknowledge.}
    }
    
    @InProceedings{10.1007/978-3-030-27520-4_20,
      author    = {Xiaoying Wu and
        Dimitri Theodoratos and
        Dimitrios Skoutas and
        Michael Lan},
      editor    = {Carlos Ordonez and
        Il{-}Yeol Song and
        Gabriele Anderst{-}Kotsis and
        A Min Tjoa and
        Ismail Khalil},
      title     = {Efficiently Computing Homomorphic Matches of Hybrid Pattern Queries
        on Large Graphs},
      booktitle = {Big Data Analytics and Knowledge Discovery - 21st International Conference,
        DaWaK 2019, Linz, Austria, August 26-29, 2019, Proceedings},
      series    = {Lecture Notes in Computer Science},
      volume    = {11708},
      pages     = {279--295},
      publisher = {Springer},
      year      = {2019},
      url       = {https://doi.org/10.1007/978-3-030-27520-4\_20},
      doi       = {10.1007/978-3-030-27520-4\_20},
    abstract="In this paper, we address the problem of efficiently finding homomorphic matches for hybrid patterns over large data graphs. Finding matches for patterns in data graphs is of fundamental importance for graph analytics. In hybrid patterns, each edge may correspond either to an edge or a path in the data graph, thus allowing for higher expressiveness and flexibility in query formulation. We introduce the concept of answer graph to compactly represent the query results and exploit computation sharing. We design a holistic bottom-up algorithm called GPM, which greatly reduces the number of intermediate results, leading to significant performance gains. GPM directly processes child constraints in the given query instead of resorting to a post-processing procedure. An extensive experimental evaluation using both real and synthetic datasets shows that our methods evaluate hybrid patterns upÂ to several orders of magnitude faster than existing algorithms and exhibit much better scalability.",
    isbn="978-3-030-27520-4",
    OPTnote="We introduce the concept of answer graph to encode all the possible homomorphisms from a pattern to the graph. By losslessly summarizing the matches of a given pattern, the answer graph represents results more succinctly. Similar to factorized representations of query results studied in the context of classical and probabilistic databases [11], the answer graph exploits computation sharing to reduce redundancy in the representation and computation of query results... The answer graph   𝐺𝐴  losslessly summarizes all the occurrences of Q on G. It exploits computation sharing to reduce redundancy in the representation and computation of query results. The concept has analogies to the factorized representation of query results studied in the context of classical databases and probabilistic databases [11]. A useful property of   𝐺𝐴  is that through a top-down traversal, the answer of Q on G can be obtained in time linear to the total number of occurrences of Q on G. Also, the cardinality of the query answer can be calculated without explicitly enumerating the occurrences of Q on G. Other benefits of succinct representations of query results include the possibility of speeding up subsequent data analysis [11]."
    }
    
    @inproceedings{DBLP:journals/corr/GurovM15,
      author    = {Dilian Gurov and
                   Minko Markov},
      editor    = {Ralph Matthes and
                   Matteo Mio},
      title     = {Self-Correlation and Maximum Independence in Finite Relations},
      booktitle = {Proceedings Tenth International Workshop on Fixed Points in Computer
                   Science, {FICS} 2015, Berlin, Germany, September 11-12, 2015},
      series    = {{EPTCS}},
      volume    = {191},
      pages     = {60--74},
      year      = {2015},
      url       = {https://doi.org/10.4204/EPTCS.191.7},
      doi       = {10.4204/EPTCS.191.7},
      timestamp = {Wed, 12 Sep 2018 01:05:15 +0200},
      biburl    = {https://dblp.org/rec/journals/corr/GurovM15.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org},
      OPTnote = {An independent partition of the set of attributes S of a finite relation R is any partition X of S such that the join of the projections of R over the elements of X yields R... A subset of S is termed self-correlated if there is a value of each of its attributes such that no tuple of R contains all those values. This paper uncovers a connection between independence and self-correlation, showing that the maximum independent partition is the least fixed point of a certain inflationary transformer alpha that operates on the finite lattice of partitions of S. alpha is defined via the minimal self-correlated subsets of S... future work:  investigate approximate relational factorisation.... The approach of [10] to the problem of computing the prime factors is “horizontal splitting” of the given relation using the selection operation from relational algebra. The approach of this paper to that same problem is quite different. We utilise “vertical splitting”, using the projection operation of relational algebra. The theoretical foundation of our approach is based on the concept of self-correlation of a subset of the attributes; that concept has no analogue in [10].}
    }
    
    @inproceedings{10.1145/3102254.3102260,
    author = {Karim, Farah and Mami, Mohamed Nadjib and Vidal, Maria-Esther and Auer, S\"{o}ren},
    title = {Large-Scale Storage and Query Processing for Semantic Sensor Data},
    year = {2017},
    isbn = {9781450352253},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3102254.3102260},
    doi = {10.1145/3102254.3102260},
    abstract = {Nowadays, there is a rapid increase in the number of sensor data produced by a wide
    variety of devices and sensors. Collections of sensor data can be semantically described
    using ontologies, e.g., the Semantic Sensor Network (SSN) ontology. Albeit semantically
    enriched, the volume of semantic sensor data is considerably larger than raw sensor
    data. Moreover, some measurement values can be observed several times, and a large
    number of repeated facts can be generated. We devise a compact or factorized representation
    of semantic sensor data, where repeated values are represented only once. To scale
    up to large datasets, tabular representation is utilized to store and manage factorized
    semantic sensor data using Big data technologies. We empirically study the effectiveness
    of the proposed factorized representation of semantic sensor data, and the impact
    of factorizing semantic sensor data on query processing. Furthermore, we evaluate
    the effects of storing RDF factorized data on state-of-the-art RDF engines and in
    the proposed tabular-based representation. Results suggest that factorization techniques
    empower storage and query processing of sensor data, and execution time can be reduced
    by up to two orders of magnitude.},
    booktitle = {Proceedings of the 7th International Conference on Web Intelligence, Mining and Semantics},
    articleno = {8},
    numpages = {12},
    keywords = {data factorization, query execution, linked sensor data},
    location = {Amantea, Italy},
    series = {WIMS '17},
    OPTnote = {We present a solution to the problem of factorizing RDF graphs describing semantic sensor data...define the algorithm that solves the problem of query evaluation on a factorized RDF graph...Factorization techniques have been utilized for optimization of relational data and SQL query processing [3, 4]...We build on these experimental results and proposed factorization technique tailored for semantically described sensor data.}
    }
    
    
    @article{DBLP:journals/jiis/KarimVA21,
      author    = {Farah Karim and
                   Maria{-}Esther Vidal and
                   S{\"{o}}ren Auer},
      title     = {Compact representations for efficient storage of semantic sensor data},
      journal   = {J. Intell. Inf. Syst.},
      volume    = {57},
      number    = {2},
      pages     = {203--228},
      year      = {2021},
      url       = {https://doi.org/10.1007/s10844-020-00628-3},
      doi       = {10.1007/s10844-020-00628-3},
      timestamp = {Wed, 06 Oct 2021 15:43:00 +0200},
      biburl    = {https://dblp.org/rec/journals/jiis/KarimVA21.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org},
    OPTnote = {We propose a compact or factorized representation of semantic sensor data, where repeated measure- ment values are described only once. Furthermore, these compact representations are able to enhance the storage and processing of semantic sensor data. To scale up to large datasets, factorization based, tabular representations are exploited to store and manage factorized semantic sensor data using Big Data technologies....In this work, we propose the Compacting Semantic Sensor Data (CSSD) approach for efficient storage and processing of semantic sensor data. The CSSD approach is based on factorizing the data and storing only a compact or factorized representation of semantic sensor data, where repeated values are represented only once. In addition, uni- versal (Ullman 1984) and Class Template (CT) based tabular representations leveraging the columnar-oriented Parquet storage format are utilized to scale up to even larger RDF datasets. The effectiveness of the proposed factorization techniques are empirically stud- ied, as well as the impact of factorizing semantic sensor data on query processing using LinkedSensorData benchmark (Patni et al. 2010)... SPARQL query rewriting techniques against factorized sensor data;  }
    }
    
    @inproceedings{DBLP:conf/edbt/Abul-BasherYGCC21,
      author    = {Zahid Abul{-}Basher and
                   Nikolay Yakovets and
                   Parke Godfrey and
                   Stanley Clark and
                   Mark H. Chignell},
      editor    = {Yannis Velegrakis and
                   Demetris Zeinalipour{-}Yazti and
                   Panos K. Chrysanthis and
                   Francesco Guerra},
      title     = {Answer Graph: Factorization Matters in Large Graphs},
      booktitle = {Proceedings of the 24th International Conference on Extending Database
                   Technology, {EDBT} 2021, Nicosia, Cyprus, March 23 - 26, 2021},
      pages     = {493--498},
      publisher = {OpenProceedings.org},
      year      = {2021},
      url       = {https://doi.org/10.5441/002/edbt.2021.57},
      doi       = {10.5441/002/edbt.2021.57},
      timestamp = {Sat, 20 Mar 2021 10:29:38 +0100},
      biburl    = {https://dblp.org/rec/conf/edbt/Abul-BasherYGCC21.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org},
      OPTnote = {In [3], the authors introduce the concept of factorization as a query- optimization technique for relational databases. Their technique is designed, and works exceptionally well, for schema and queries for which cross products of projections of the answer tuples all show up as answer tuples. This happens, for instance, in schema not in fourth normal form. Evaluating for these projected tuples first and then cross-producting them later can be a much more efficient strategy. Deciding how best to factorize—how to project into sub-tuples—is difficult, however.
    For CQs, this last part is trivial: the factorization of the embed- ding tuples is fully down to component node pairs, corresponding to the labeled edges. This is our answer graph.1 While factorization is sometimes a significant win for evaluating relational queries, it is virtually always a win for evaluating graph CQs.},
      abstract = {Our answer-graph method to evaluate SPARQL conjunctive queries (CQs) finds a factorized answer set first, an answer graph, and then finds the embedding tuples from this. This approach can reduce greatly the cost to evaluate CQs. This affords a second advantage: we can construct a cost-based planner. We present the answer- graph approach, and overview our prototype system, Wireframe. We then offer proof of concept via a micro-benchmark over the YAGO2s dataset with two prevalent shapes of queries, snowflake and diamond. We compare Wireframe’s performance over these against PostgreSQL, Virtuoso, MonetDB, and Neo4J to illustrate the performance advantages of our answer-graph approach.},
      OPTnote = {Best short paper award}
    }
    
    
    
    
    
    ################################################
    ### COMPLEX COMPUTATION OVER RELATIONAL DBs ####
    ################################################
    
    @article{DBLP:journals/corr/abs-1901-03633,
      author    = {Florent Capelli and
                   Nicolas Crosetti and
                   Joachim Niehren and
                   Jan Ramon},
      title     = {Dependency Weighted Aggregation on Factorized Databases},
      journal   = {CoRR},
      volume    = {abs/1901.03633},
      year      = {2019},
      url       = {http://arxiv.org/abs/1901.03633},
      eprinttype = {arXiv},
      eprint    = {1901.03633},
      timestamp = {Fri, 01 Feb 2019 13:39:59 +0100},
      biburl    = {https://dblp.org/rec/journals/corr/abs-1901-03633.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org},
      OPTnote = {Hence, we based our approach on the framework of factorized databases of Olteanu and Z ́avodny ́ [OZ12]. A factorized database is a data structure that allows to represent a table in a factorized way that can be much smaller than the original table. More precisely, a factorized representation of a table may be seen as a circuit whose inputs are tables with one column and performing only Cartesian products and disjoint unions that we will refer to as {⊎,×}-circuits in this paper. Our central theorem, Theorem 4.6, shows that a given weighting of a table represented by a {⊎, ×}-circuit can be canonically represented as a weighting of the edges of the circuit. This connection gives us a direct way of rewriting a linear program whose variables are the tuples of a table represented by a {⊎, ×}-circuit into a linear program whose variables are the edges of the circuit having the same optimal value.
    Several classes of conjunctive queries are known to admit polynomial size {⊎,×}-circuits, the most notorious one being conjunctive queries with bounded fractional hypertree width [OZ15].... To solve ground linear programs efficiently, we will work on factorized representations of relations. We use a generalization of the framework of factorized databases introduced by Olteanu et al. [OZ12].}
    }
    
    
    @misc{huang2021reptile,
          title={Reptile: Aggregation-level Explanations for Hierarchical Data}, 
          author={Zezhou Huang and Eugene Wu},
          year={2021},
          eprint={2103.07037},
          journal   = {CoRR},
          volume    = {abs/2103.07037},
          url       = {https://arxiv.org/abs/2103.07037},
          eprinttype = {arXiv},  
          abstract = {Recent query explanation systems help users understand anomalies in aggregation results by proposing predicates that describe input records that, if deleted, would resolve the anomalies. However, it can be difficult for users to understand how a predicate was chosen, and these approaches are limited to errors that can be resolved through deletion. In contrast, data errors may be due to group-wise errors, such as missing records or systematic value errors. This paper presents Reptile, an explanation system for hierarchical data. Given an anomalous aggregate query result, Reptile recommends the next drill-down attribute,and ranks the drill-down groups based on the extent repairing the group's statistics to its expected values resolves the anomaly. Reptile efficiently trains a multi-level model that leverages the data's hierarchy to estimate the expected values, and uses a factorised representation of the feature matrix to remove redundancies due to the data's hierarchical structure. We further extend model training to support factorised data, and develop a suite of optimizations that leverage the data's hierarchical structure. Reptile reduces end-to-end runtimes by more than 6 times compared to a Matlab-based implementation, correctly identifies 21/30 data errors in John Hopkin's COVID-19 data, and correctly resolves 20/22 complaints in a user study using data and researchers from Columbia University's Financial Instruments Sector Team.},
          OPTnote = {Factorised Feature Matrix: We now outline the construction of the factorised feature matrix, using Figure 3c as the example. We refer readers to Olteanu et al. [41] for a complete procedure...  Instead of materializing a feature matrix exponential in the number of hierarchies, Reptile com- putes a succinct factorised matrix representation [41] that reduces the matrix representation by orders of magnitude. We extend prior work [51, 52], which developed model training procedures over factorised matrices derived from join queries, to matrices based on join-aggregation queries that exhibit fewer redundancies. We fur- ther design factorised matrix multiplication operators, and develop a suite of novel work-sharing and caching-based optimizations....We adapt factorized representations to compactly represent the feature matrix, and extend matrix operations to support factor- ized representations. We develop precomputation, work sharing, and caching optimizations to further accelerate successive drill-down operations....On synthetic data, our factorized matrix operations accelerate matrix materialization and gram matrix computations by orders of magnitude, and work-sharing reduces runtimes by 4× over LMFAO [51]....Factorised Representation: Factorised Representation [41] re- duces redundancies due to functional dependencies, and has been used to optimize model training (linear regression [52], decision tree [27] and Rk-mean [12]) over factorised matrices derived from join queries. Reptile extends prior work [51, 52] to matrices based on join-aggregation queries that exhibit fewer redundancies, sup- ports extra operations including right and left multiplication, and further exploits the hierarchical structure for optimization.}
    }
    
    @article{10.1145/3375661,
    author = {Khamis, Mahmoud Abo and Ngo, Hung Q. and Nguyen, Xuanlong and Olteanu, Dan and Schleich, Maximilian},
    title = {Learning Models over Relational Data Using Sparse Tensors and Functional Dependencies},
    year = {2020},
    issue_date = {July 2020},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {45},
    number = {2},
    issn = {0362-5915},
    url = {https://doi.org/10.1145/3375661},
    doi = {10.1145/3375661},
    abstract = {Integrated solutions for analytics over relational databases are of great practical
    importance as they avoid the costly repeated loop data scientists have to deal with
    on a daily basis: select features from data residing in relational databases using
    feature extraction queries involving joins, projections, and aggregations; export
    the training dataset defined by such queries; convert this dataset into the format
    of an external learning tool; and train the desired model using this tool. These integrated
    solutions are also a fertile ground of theoretically fundamental and challenging problems
    at the intersection of relational and statistical data models.This article introduces
    a unified framework for training and evaluating a class of statistical learning models
    over relational databases. This class includes ridge linear regression, polynomial
    regression, factorization machines, and principal component analysis. We show that,
    by synergizing key tools from database theory such as schema information, query structure,
    functional dependencies, recent advances in query evaluation algorithms, and from
    linear algebra such as tensor and matrix operations, one can formulate relational
    analytics problems and design efficient (query and data) structure-aware algorithms
    to solve them.This theoretical development informed the design and implementation
    of the AC/DC system for structure-aware learning. We benchmark the performance of
    AC/DC against R, MADlib, libFM, and TensorFlow. For typical retail forecasting and
    advertisement planning applications, AC/DC can learn polynomial regression models
    and factorization machines with at least the same accuracy as its competitors and
    up to three orders of magnitude faster than its competitors whenever they do not run
    out of memory, exceed 24-hour timeout, or encounter internal design limitations.},
    journal = {ACM Trans. Database Syst.},
    month = {jun},
    articleno = {7},
    numpages = {66},
    keywords = {functional dependencies, functional aggregate queries, tensors, model reparameterization, In-database analytics},
    OPTnote = {Short version appeared in PODS 2019 and was selected as best of the conference}
    }
    
    @inproceedings{10.1145/3209889.3209896,
    author = {Khamis, Mahmoud Abo and Ngo, Hung Q. and Nguyen, XuanLong and Olteanu, Dan and Schleich, Maximilian},
    title = {AC/DC: In-Database Learning Thunderstruck},
    year = {2018},
    isbn = {9781450358286},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3209889.3209896},
    doi = {10.1145/3209889.3209896},
    abstract = {We report on the design and implementation of the AC/DC gradient descent solver for
    a class of optimization problems over normalized databases. AC/DC decomposes an optimization
    problem into a set of aggregates over the join of the database relations. It then
    uses the answers to these aggregates to iteratively improve the solution to the problem
    until it converges.The challenges faced by AC/DC are the large database size, the
    mixture of continuous and categorical features, and the large number of aggregates
    to compute. AC/DC addresses these challenges by employing a sparse data representation,
    factorized computation, problem reparameterization under functional dependencies,
    and a data structure that supports shared computation of aggregates.To train polynomial
    regression models and factorization machines of up to 154K features over the natural
    join of all relations from a real-world dataset of up to 86M tuples, AC/DC needs up
    to 30 minutes on one core of a commodity machine. This is up to three orders of magnitude
    faster than its competitors R, MadLib, libFM, and TensorFlow whenever they finish
    and thus do not exceed memory limitation, 24-hour timeout, or internal design limitations.},
    booktitle = {Proceedings of the Second Workshop on Data Management for End-To-End Machine Learning},
    articleno = {8},
    numpages = {10},
    location = {Houston, TX, USA},
    series = {DEEM'18}
    }
    
    @article{10.1145/3129246,
    author = {Aberger, Christopher R. and Lamb, Andrew and Tu, Susan and N\"{o}tzli, Andres and Olukotun, Kunle and R\'{e}, Christopher},
    title = {EmptyHeaded: A Relational Engine for Graph Processing},
    year = {2017},
    issue_date = {November 2017},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {42},
    number = {4},
    issn = {0362-5915},
    url = {https://doi.org/10.1145/3129246},
    doi = {10.1145/3129246},
    abstract = {There are two types of high-performance graph processing engines: low- and high-level
    engines. Low-level engines (Galois, PowerGraph, Snap) provide optimized data structures
    and computation models but require users to write low-level imperative code, hence
    ensuring that efficiency is the burden of the user. In high-level engines, users write
    in query languages like datalog (SociaLite) or SQL (Grail). High-level engines are
    easier to use but are orders of magnitude slower than the low-level graph engines.
    We present EmptyHeaded, a high-level engine that supports a rich datalog-like query
    language and achieves performance comparable to that of low-level engines. At the
    core of EmptyHeaded’s design is a new class of join algorithms that satisfy strong
    theoretical guarantees, but have thus far not achieved performance comparable to that
    of specialized graph processing engines. To achieve high performance, EmptyHeaded
    introduces a new join engine architecture, including a novel query optimizer and execution
    engine that leverage single-instruction multiple data (SIMD) parallelism. With this
    architecture, EmptyHeaded outperforms high-level approaches by up to three orders
    of magnitude on graph pattern queries, PageRank, and Single-Source Shortest Paths
    (SSSP) and is an order of magnitude faster than many low-level baselines. We validate
    that EmptyHeaded competes with the best-of-breed low-level engine (Galois), achieving
    comparable performance on PageRank and at most 3\texttimes{} worse performance on SSSP. Finally,
    we show that the EmptyHeaded design can easily be extended to accommodate a standard
    resource description framework (RDF) workload, the LUBM benchmark. On the LUBM benchmark,
    we show that EmptyHeaded can compete with and sometimes outperform two high-level,
    but specialized RDF baselines (TripleBit and RDF-3X), while outperforming MonetDB
    by up to three orders of magnitude and LogicBlox by up to two orders of magnitude.},
    journal = {ACM Trans. Database Syst.},
    month = {oct},
    articleno = {20},
    numpages = {44},
    keywords = {generalized hypertree decomposition, single-instruction multiple data, SIMD, Worst-case optimal join, graph processing, GHD},
    OPTnote = {Aggregations over GHDs. Previous work has investigated aggregations over hypertree decom- positions [22, 54]. EmptyHeaded adopts this previous work in a straightforward way. }
    }
    
    
    
    @inproceedings{10.1145/2902251.2902293,
    author = {Joglekar, Manas R. and Puttagunta, Rohan and R\'{e}, Christopher},
    title = {AJAR: Aggregations and Joins over Annotated Relations},
    year = {2016},
    isbn = {9781450341912},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2902251.2902293},
    doi = {10.1145/2902251.2902293},
    abstract = {We study a class of aggregate-join queries with multiple aggregation operators evaluated
    over annotated relations. We show that straightforward extensions of standard multiway
    join algorithms and generalized hypertree decompositions (GHDs) provide best-known
    runtime guarantees. In contrast, prior work uses bespoke algorithms and data structures
    and does not match these guarantees. We extend the standard techniques by providing
    a complete characterization of (1) the set of orderings equivalent to a given ordering
    and (2) the set of GHDs valid with respect to the given ordering, i.e., GHDs that
    correctly answer a given aggregate-join query when provided to (simple variants of)
    standard join algorithms. We show by example that previous approaches are incomplete.
    The key technical consequence of our characterizations is a decomposition of a valid
    GHD into a set of (smaller) unconstrained GHDs, i.e., into a set of GHDs of sub-queries
    without aggregations. Since this decomposition is comprised of unconstrained GHDs,
    we are able to connect to the wide literature on GHDs for join query processing, thereby
    obtaining improved runtime bounds, MapReduce variants, and an efficient method to
    find approximately optimal GHDs.},
    booktitle = {Proceedings of the 35th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems},
    pages = {91–106},
    numpages = {16},
    keywords = {aggregation, join query, semiring, fractional hypertreewidth, generalized hypertree decomposition},
    location = {San Francisco, California, USA},
    series = {PODS '16},
    OPTnote = {There is a standard modifica- tion to Yannakakis to handle aggregations [29], but the classic analysis provides only a O(IN · OUT) bound. Bakibayev, Ko- cisky, Olteanu, and Zavodny study aggregation-join queries in factorized databases [6], and later Olteanu and Zavodny con- nected factorized databases and GHDs/GHDJoin [22]. They develop the intuition that if output attributes are above non- output attributes, the +OUT runtime is preserved; we use the same intuition to develop and analyze AggroGHDJoin, a variant to GHDJoin for aggregate-join queries.}
    }
    
    @inproceedings{10.1145/2882903.2882939,
    author = {Schleich, Maximilian and Olteanu, Dan and Ciucanu, Radu},
    title = {Learning Linear Regression Models over Factorized Joins},
    year = {2016},
    isbn = {9781450335317},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2882903.2882939},
    doi = {10.1145/2882903.2882939},
    abstract = {We investigate the problem of building least squares regression models over training
    datasets defined by arbitrary join queries on database tables. Our key observation
    is that joins entail a high degree of redundancy in both computation and data representation,
    which is not required for the end-to-end solution to learning over joins.We propose
    a new paradigm for computing batch gradient descent that exploits the factorized computation
    and representation of the training datasets, a rewriting of the regression objective
    function that decouples the computation of cofactors of model parameters from their
    convergence, and the commutativity of cofactor computation with relational union and
    projection. We introduce three flavors of this approach: F/FDB computes the cofactors
    in one pass over the materialized factorized join; Favoids this materialization and
    intermixes cofactor and join computation; F/SQL expresses this mixture as one SQL
    query.Our approach has the complexity of join factorization, which can be exponentially
    lower than of standard joins. Experiments with commercial, public, and synthetic datasets
    show that it outperforms MADlib, Python StatsModels, and R, by up to three orders
    of magnitude.},
    booktitle = {Proceedings of the 2016 International Conference on Management of Data},
    pages = {3–18},
    numpages = {16},
    keywords = {linear regression, join processing, factorized databases},
    location = {San Francisco, California, USA},
    series = {SIGMOD '16}
    }
    
    @inproceedings{DBLP:conf/aistats/CurtinM0NOS20,
      author    = {Ryan R. Curtin and
                   Benjamin Moseley and
                   Hung Q. Ngo and
                   XuanLong Nguyen and
                   Dan Olteanu and
                   Maximilian Schleich},
      editor    = {Silvia Chiappa and
                   Roberto Calandra},
      title     = {Rk-means: Fast Clustering for Relational Data},
      booktitle = {The 23rd International Conference on Artificial Intelligence and Statistics,
                   {AISTATS} 2020, 26-28 August 2020, Online [Palermo, Sicily, Italy]},
      series    = {Proceedings of Machine Learning Research},
      volume    = {108},
      pages     = {2742--2752},
      publisher = {{PMLR}},
      year      = {2020},
      url       = {http://proceedings.mlr.press/v108/curtin20a.html},
      timestamp = {Mon, 29 Jun 2020 18:03:58 +0200},
      biburl    = {https://dblp.org/rec/conf/aistats/CurtinM0NOS20.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    @inproceedings{DBLP:conf/pods/KhamisNR16,
      author    = {Mahmoud Abo Khamis and
                   Hung Q. Ngo and
                   Atri Rudra},
      editor    = {Tova Milo and
                   Wang{-}Chiew Tan},
      title     = {{FAQ:} Questions Asked Frequently},
      booktitle = {Proceedings of the 35th {ACM} {SIGMOD-SIGACT-SIGAI} Symposium on Principles
                   of Database Systems, {PODS} 2016, San Francisco, CA, USA, June 26
                   - July 01, 2016},
      pages     = {13--28},
      publisher = {{ACM}},
      year      = {2016},
      url       = {https://doi.org/10.1145/2902251.2902280},
      doi       = {10.1145/2902251.2902280},
      timestamp = {Thu, 14 Oct 2021 10:38:21 +0200},
      biburl    = {https://dblp.org/rec/conf/pods/KhamisNR16.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org},
      OPTnote = {Bakibayev et al. [9] and Olteanu and Za ́vodny ́ [43] intro- duced the notion of factorized databases, and showed how one can efficiently compute join and aggregates over fac- torized databases. In hindsight there is much in common between their approach and InsideOut applied to the sin- gle semiring case of FAQ-SS. Both approaches have the same runtime complexity, because both are dynamic pro- gramming algorithms, InsideOut is bottom-up, and factor- ized database computation is top-down (memoized). 
    The FAQ framework is more general in that it can handle multiple aggregate types. Our contribution also involves the characterization of EVO and an approximation algorithm for faqw. On the other hand, aspects of factorized database that FAQ does not handle include the evaluation of SQL queries and output size bounds on the factorized representations... However, inspired by Olteanu and Za ́vodny ́ [43] we can first compute the output in the factorized representation, and then report it.}
    }
    
    @inproceedings{DBLP:conf/sigmod/SchleichOK0N19,
      author    = {Maximilian Schleich and
                   Dan Olteanu and
                   Mahmoud Abo Khamis and
                   Hung Q. Ngo and
                   XuanLong Nguyen},
      editor    = {Peter A. Boncz and
                   Stefan Manegold and
                   Anastasia Ailamaki and
                   Amol Deshpande and
                   Tim Kraska},
      title     = {A Layered Aggregate Engine for Analytics Workloads},
      booktitle = {Proceedings of the 2019 International Conference on Management of
                   Data, {SIGMOD} Conference 2019, Amsterdam, The Netherlands, June 30
                   - July 5, 2019},
      pages     = {1642--1659},
      publisher = {{ACM}},
      year      = {2019},
      url       = {https://doi.org/10.1145/3299869.3324961},
      doi       = {10.1145/3299869.3324961},
      timestamp = {Thu, 14 Oct 2021 10:11:37 +0200},
      biburl    = {https://dblp.org/rec/conf/sigmod/SchleichOK0N19.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    @article{DBLP:journals/tods/KhamisCMNNOS20,
      author    = {Mahmoud Abo Khamis and
                   Ryan R. Curtin and
                   Benjamin Moseley and
                   Hung Q. Ngo and
                   XuanLong Nguyen and
                   Dan Olteanu and
                   Maximilian Schleich},
      title     = {Functional Aggregate Queries with Additive Inequalities},
      journal   = {{ACM} Trans. Database Syst.},
      volume    = {45},
      number    = {4},
      pages     = {17:1--17:41},
      year      = {2020},
      url       = {https://doi.org/10.1145/3426865},
      doi       = {10.1145/3426865},
      timestamp = {Thu, 14 Oct 2021 09:33:15 +0200},
      biburl    = {https://dblp.org/rec/journals/tods/KhamisCMNNOS20.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    
    
    ####################
    #### PROVENANCE ####
    ####################
    
    @article{10.14778/3436905.3436909,
    author = {Zheng, Nan and Ives, Zachary G.},
    title = {Compact, Tamper-Resistant Archival of Fine-Grained Provenance},
    year = {2020},
    issue_date = {December 2020},
    publisher = {VLDB Endowment},
    volume = {14},
    number = {4},
    issn = {2150-8097},
    url = {https://doi.org/10.14778/3436905.3436909},
    doi = {10.14778/3436905.3436909},
    abstract = {Data provenance tools aim to facilitate reproducible data science and auditable data
    analyses, by tracking the processes and inputs responsible for each result of an analysis.
    Fine-grained provenance further enables sophisticated reasoning about why individual
    output results appear or fail to appear. However, for reproducibility and auditing,
    we need a provenance archival system that is tamper-resistant, and efficiently stores
    provenance for computations computed over time (i.e., it compresses repeated results).
    We study this problem, developing solutions for storing fine-grained provenance in
    relational storage systems while both compressing and protecting it via cryptographic
    hashes. We experimentally validate our proposed solutions using both scientific and
    OLAP workloads.},
    journal = {Proc. VLDB Endow.},
    month = {dec},
    pages = {485–497},
    numpages = {13},
    OPTnote = {Prior work [23] has studied factorized representations [29] to reduce overall provenance size. Our scenario is somewhat more complex: PROVision attempts to compute results and provenance efficiently, and thus includes a cost-based query optimizer. We opportunistically exploit shared subexpressions as they occur... Lee and co-authors [23] reduce provenance storage by creating more efficient factorized query ex- pressions [29].1 Their PUG system factors provenance into a d-tree representation [29] before storing it. Similarly, Bao et al. [6] develop strategies for factoring out provenance storage for common query expressions. }
    }
    
    @inproceedings{10.1145/2396761.2398439,
    author = {Bao, Zhifeng and K\"{o}hler, Henning and Wang, Liwei and Zhou, Xiaofang and Sadiq, Shazia},
    title = {Efficient Provenance Storage for Relational Queries},
    year = {2012},
    isbn = {9781450311564},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/2396761.2398439},
    doi = {10.1145/2396761.2398439},
    abstract = {Provenance information is vital in many application areas as it helps explain data
    lineage and derivation. However, storing fine-grained provenance information can be
    expensive. In this paper, we present a framework for storing provenance information
    relating to data derived via database queries. In particular, we first propose a provenance
    tree data structure which matches the query structure and thereby presents a possibility
    to avoid redundant storage of information regarding the derivation process. Then we
    investigate two approaches for reducing storage costs. The first approach utilizes
    two ingenious rules to achieve reduction on provenance trees. The second one is a
    dynamic programming solution, which provides a way of optimizing the selection of
    query tree nodes where provenance information should be stored. The optimization algorithm
    runs in polynomial time in the query size and is linear in the size of the provenance
    information, thus enabling provenance tracking and optimization without incurring
    large overheads. Experiments show that our approaches guarantee significantly lower
    storage costs than existing approaches.},
    booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
    pages = {1352–1361},
    numpages = {10},
    keywords = {provenance storage},
    location = {Maui, Hawaii, USA},
    series = {CIKM '12}
    }
    
    
    @article{DBLP:journals/vldb/LeeLG19,
      author    = {Seokki Lee and
                   Bertram Lud{\"{a}}scher and
                   Boris Glavic},
      title     = {{PUG:} a framework and practical implementation for why and why-not
                   provenance},
      journal   = {{VLDB} J.},
      volume    = {28},
      number    = {1},
      pages     = {47--71},
      year      = {2019},
      url       = {https://doi.org/10.1007/s00778-018-0518-5},
      doi       = {10.1007/s00778-018-0518-5},
      timestamp = {Wed, 13 Feb 2019 23:02:12 +0100},
      biburl    = {https://dblp.org/rec/journals/vldb/LeeLG19.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org},
      OPTnote = {first practical approach for answering such questions for queries with negation.. PUG (Provenance Unification through Graphs) system takes a provenance question and Datalog query as an input and generates a Datalog program that computes an explanation, i.e., the part of the provenance that is relevant to answer the question. Furthermore, we demonstrate how a desirable factorization of provenance can be achieved by rewriting an input query... We exploit this fact by rewriting the input pro- gram to generate more concise, but equivalent, provenance. This is akin to factorization of provenance polynomials in the semiring model and utilizes factorized databases tech- niques [33,34]... Entire Section 9 devoted to provenance factorisation... "extend our approach to produce concise, factorized representations of provenance."}
    }
    
    
    @article{10.1145/3277006.3277017,
    author = {Deutch, Daniel and Frost, Nave and Gilad, Amir},
    title = {Natural Language Explanations for Query Results},
    year = {2018},
    issue_date = {March 2018},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {47},
    number = {1},
    issn = {0163-5808},
    url = {https://doi.org/10.1145/3277006.3277017},
    doi = {10.1145/3277006.3277017},
    abstract = {Multiple lines of research have developed Natural Language (NL) interfaces for formulating
    database queries. We build upon this work, but focus on presenting a highly detailed
    form of the answers in NL. The answers that we present are importantly based on the
    provenance of tuples in the query result, detailing not only the results but also
    their explanations. We develop a novel method for transforming provenance information
    to NL, by leveraging the original NL query structure. Furthermore, since provenance
    information is typically large and complex, we present two solutions for its effective
    presentation as NL text: one that is based on provenance factorization, with novel
    desiderata relevant to the NL case, and one that is based on summarization.},
    journal = {SIGMOD Rec.},
    month = {sep},
    pages = {42–49},
    numpages = {8},
    OPTnote = {As observed already in previous work [4, 18], different assignments (explanations) may have signifi- cant parts in common, and this can be leveraged in a fac- torization that groups together multiple occurrences. In our example, we can e.g. factorize explanations based on author, paper name, conference name or year. Importantly, we im- pose a novel constraint on the factorizations that we look for (which we call compatibility), intuitively capturing that their structure is consistent with a partial order defined by the parse tree of the question. This constraint is needed so that we can translate the factorization back to an NL an- swer whose structure is similar to that of the question.... We observe a tight correspondence between factorization and summa- rization: every factorization gives rise to multiple possible summarizations, each obtained by counting the number of sub-explanations that are “factorized together”...Instead, we propose two solu- tions: the first based on the idea of provenance factorization [18, 4], and the second leveraging factorization to provide a summarized form. }
    }
    
    @article{DBLP:journals/vldb/DeutchFG20,
      author    = {Daniel Deutch and
                   Nave Frost and
                   Amir Gilad},
      title     = {Explaining Natural Language query results},
      journal   = {{VLDB} J.},
      volume    = {29},
      number    = {1},
      pages     = {485--508},
      year      = {2020},
      url       = {https://doi.org/10.1007/s00778-019-00584-7},
      doi       = {10.1007/s00778-019-00584-7},
      timestamp = {Thu, 06 Feb 2020 18:13:19 +0100},
      biburl    = {https://dblp.org/rec/journals/vldb/DeutchFG20.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org},
      OPTnote = {conference version received VLDB 2017 Best Paper Award}
    }
    
    @article{DBLP:journals/pvldb/DeutchFG17,
      author    = {Daniel Deutch and
                   Nave Frost and
                   Amir Gilad},
      title     = {Provenance for Natural Language Queries},
      journal   = {Proc. {VLDB} Endow.},
      volume    = {10},
      number    = {5},
      pages     = {577--588},
      year      = {2017},
      url       = {http://www.vldb.org/pvldb/vol10/p577-deutch.pdf},
      doi       = {10.14778/3055540.3055550},
      timestamp = {Sat, 25 Apr 2020 13:58:56 +0200},
      biburl    = {https://dblp.org/rec/journals/pvldb/DeutchFG17.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    
    @inproceedings{10.1145/3035918.3035926,
    author = {Chen, Chen and Lehri, Harshal Tushar and Kuan Loh, Lay and Alur, Anupam and Jia, Limin and Loo, Boon Thau and Zhou, Wenchao},
    title = {Distributed Provenance Compression},
    year = {2017},
    isbn = {9781450341974},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3035918.3035926},
    doi = {10.1145/3035918.3035926},
    abstract = {Network provenance, which records the execution history of network events as meta-data,
    is becoming increasingly important for network accountability and failure diagnosis.
    For example, network provenance may be used to trace the path that a message traversed
    in a network, or to reveal how a particular routing entry was derived and the parties
    involved in its derivation. A challenge when storing the provenance of a live network
    is that the large number of the arriving messages may incur substantial storage overhead.
    In this paper, we explore techniques to dynamically compress distributed provenance
    stored at scale. Logically, the compression is achieved by grouping equivalent provenance
    trees and maintaining only one concrete copy for each equivalence class. To efficiently
    identify equivalent provenance, we (1) introduce distributed event-based linear programs
    (DELP) to specify distributed network applications, and (2) statically analyze DELPs
    to allow for quick detection of provenance equivalence at runtime. Our experimental
    results demonstrate that our approach leads to significant storage reduction and query
    latency improvement over alternative approaches.},
    booktitle = {Proceedings of the 2017 ACM International Conference on Management of Data},
    pages = {203–218},
    numpages = {16},
    keywords = {storage, provenance, static analysis, distributed systems},
    location = {Chicago, Illinois, USA},
    series = {SIGMOD '17},
    abstract = {Network provenance, which records the execution history of network events as meta-data, is becoming increasingly important for network accountability and failure diagnosis. For example, network provenance may be used to trace the path that a message traversed in a network, or to reveal how a particular routing entry was derived and the parties involved in its derivation. A challenge when storing the provenance of a live network is that the large number of ar- riving messages may incur substantial storage overhead. In this paper, we explore techniques to dynamically compress distributed provenance stored at scale. Logically, compres- sion is achieved by grouping equivalent provenance trees and maintaining only one concrete copy for each equiva- lence class. To efficiently identify the equivalent provenance, we (1) introduce distributed event-based linear programs (DELPs) to specify distributed network applications, and (2) statically analyze DELPs to allow for quick detection of provenance equivalence at runtime. Our experimental results demonstrate that our approach leads to significant storage reduction and query latency improvement over al- ternative approaches.},
    OPTnote = {Our compression technique implicitly factorizes provenance trees at runtime before removing redundant factors among trees in the same equivalence class. Olteanu et al. [16][17] propose factorization of provenance polynomials for con- junctive queries with a new data structure called factoriza- tion tree. Polynomial factorization in [17] can be viewed as a more general form of the factorization used in the equivalence-based compression proposed in this paper. If we encode the provenance trees of each packet as polynomials, the general factorization algorithm in [17], with specialized factorization tree, would produce the same factorization re- sult in our setting. Our approach is slightly more efficient, as we can skip the factorization step by directly using the equivalence keys at runtime to group provenance trees for compression. Exploring the more general form of factor- ization in [17] for provenance of distributed queries is an interesting avenue of future work.}
    }
    
    #############
    #### IVM ####
    #############
    
    @inproceedings{10.1145/3183713.3183758,
    author = {Nikolic, Milos and Olteanu, Dan},
    title = {Incremental View Maintenance with Triple Lock Factorization Benefits},
    year = {2018},
    isbn = {9781450347037},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3183713.3183758},
    doi = {10.1145/3183713.3183758},
    abstract = {We introduce F-IVM, a unified incremental view maintenance (IVM) approach for a variety
    of tasks, including gradient computation for learning linear regression models over
    joins, matrix chain multiplication, and factorized evaluation of conjunctive queries.F-IVM
    is a higher-order IVM algorithm that reduces the maintenance of the given task to
    the maintenance of a hierarchy of increasingly simpler views. The views are functions
    mapping keys, which are tuples of input data values, to payloads, which are elements
    from a task-specific ring. Whereas the computation over the keys is the same for all
    tasks, the computation over the payloads depends on the task. F-IVM achieves efficiency
    by factorizing the computation of the keys, payloads, and updates. We implemented
    F-IVM as an extension of DBToaster. We show in a range of scenarios that it can outperform
    classical first-order IVM, DBToaster's fully recursive higher-order IVM, and plain
    recomputation by orders of magnitude while using less memory.},
    booktitle = {Proceedings of the 2018 International Conference on Management of Data},
    pages = {365–380},
    numpages = {16},
    keywords = {query optimization, incremental view maintenance, factorized representation, rings, materialized views, stream processing},
    location = {Houston, TX, USA},
    series = {SIGMOD '18}
    }
    
    @article{DBLP:journals/tods/KaraNNOZ20,
      author    = {Ahmet Kara and
                   Hung Q. Ngo and
                   Milos Nikolic and
                   Dan Olteanu and
                   Haozhe Zhang},
      title     = {Maintaining Triangle Queries under Updates},
      journal   = {{ACM} Trans. Database Syst.},
      volume    = {45},
      number    = {3},
      pages     = {11:1--11:46},
      year      = {2020},
      url       = {https://doi.org/10.1145/3396375},
      doi       = {10.1145/3396375},
      timestamp = {Thu, 08 Oct 2020 09:19:37 +0200},
      biburl    = {https://dblp.org/rec/journals/tods/KaraNNOZ20.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    
    ########################
    #### REPRESENTATION ####
    ########################
    
    
    ##############################
    #### FACTORIZED ML AND LA ####
    ##############################
    
    @inproceedings{DBLP:conf/sigmod/LiC019,
      author    = {Side Li and
                   Lingjiao Chen and
                   Arun Kumar},
      editor    = {Peter A. Boncz and
                   Stefan Manegold and
                   Anastasia Ailamaki and
                   Amol Deshpande and
                   Tim Kraska},
      title     = {Enabling and Optimizing Non-linear Feature Interactions in Factorized
                   Linear Algebra},
      booktitle = {Proceedings of the 2019 International Conference on Management of
                   Data, {SIGMOD} Conference 2019, Amsterdam, The Netherlands, June 30
                   - July 5, 2019},
      pages     = {1571--1588},
      publisher = {{ACM}},
      year      = {2019},
      url       = {https://doi.org/10.1145/3299869.3319878},
      doi       = {10.1145/3299869.3319878},
      timestamp = {Sat, 22 Jun 2019 17:10:04 +0200},
      biburl    = {https://dblp.org/rec/conf/sigmod/LiC019.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    @article{DBLP:journals/pvldb/JustoYSPK21,
      author    = {David Justo and
                   Shaoqing Yi and
                   Lukas Stadler and
                   Nadia Polikarpova and
                   Arun Kumar},
      title     = {Towards {A} Polyglot Framework for Factorized {ML}},
      journal   = {Proc. {VLDB} Endow.},
      volume    = {14},
      number    = {12},
      pages     = {2918--2931},
      year      = {2021},
      url       = {http://www.vldb.org/pvldb/vol14/p2918-justo.pdf},
      timestamp = {Fri, 27 Aug 2021 17:02:27 +0200},
      biburl    = {https://dblp.org/rec/journals/pvldb/JustoYSPK21.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org},
      OPTnote = { Industrial Track},
      OPTnote = {We extend a recent line of work in the DB world on factorized ML, which we split into 3 groups based on setting and target workloads: specific ML algorithms [33, 46, 49], in-RDBMS execution [20, 34, 48], and LA systems [23, 32, 35, 36]. Our work is complementary to all these prior works and builds on their ideas. The novelty of our Trinity is in its generality: it is the first to support factorized ML style ideas in a polyglot setting. Our work enables such novel DB+ML query optimization ideas to be implemented once but made available to multiple PL/LA systems in one go. },
      abstract = {Optimizing machine learning (ML) workloads on structured data is a key concern for data platforms. One class of optimizations called “factorized ML” helps reduce ML runtimes over multi-table datasets by pushing ML computations down through joins, avoid- ing the need to materialize such joins. The recent Morpheus system automated factorized ML to any ML algorithm expressible in lin- ear algebra (LA). But all such prior factorized ML/LA stacks are restricted by their chosen programming language (PL) and run- time environment, limiting their reach in emerging industrial data science environments with many PLs (R, Python, etc.) and even cross-PL analytics workflows. Re-implementing Morpheus from scratch in each PL/environment is a massive developability over- head for implementation, testing, and maintenance. We tackle this challenge by proposing a new system architecture, Trinity, to en- able factorized LA logic to be written only once and easily reused across many PLs/LA tools in one go. To do this in an extensible and efficient manner without costly data copies, Trinity leverages and extends an emerging industrial polyglot compiler and runtime, Or- acle’s GraalVM. Trinity enables factorized LA in multiple PLs and even cross-PL workflows. Experiments with real datasets show that Trinity is significantly faster than materialized execution (> 8x speedups in some cases), while being largely competitive to a prior single PL-focused Morpheus stack.}
      }
    
    @INPROCEEDINGS {9101671,
    author = {K. Yang and Y. Gao and L. Liang and B. Yao and S. Wen and G. Chen},
    booktitle = {2020 IEEE 36th International Conference on Data Engineering (ICDE)},
    title = {Towards Factorized {SVM} with Gaussian Kernels over Normalized Data},
    year = {2020},
    volume = {},
    issn = {},
    pages = {1453-1464},
    keywords = {support vector machines;kernel;databases;motion pictures;optimization;training;machine learning},
    doi = {10.1109/ICDE48307.2020.00129},
    url = {https://doi.ieeecomputersociety.org/10.1109/ICDE48307.2020.00129},
    publisher = {IEEE Computer Society},
    address = {Los Alamitos, CA, USA},
    month = {apr}
    }
    
    
    
    @inproceedings{DBLP:conf/sigmod/KumarNP15,
      author    = {Arun Kumar and
                   Jeffrey F. Naughton and
                   Jignesh M. Patel},
      editor    = {Timos K. Sellis and
                   Susan B. Davidson and
                   Zachary G. Ives},
      title     = {Learning Generalized Linear Models Over Normalized Data},
      booktitle = {Proceedings of the 2015 {ACM} {SIGMOD} International Conference on
                   Management of Data, Melbourne, Victoria, Australia, May 31 - June
                   4, 2015},
      pages     = {1969--1984},
      publisher = {{ACM}},
      year      = {2015},
      url       = {https://doi.org/10.1145/2723372.2723713},
      doi       = {10.1145/2723372.2723713},
      timestamp = {Tue, 06 Nov 2018 11:07:38 +0100},
      biburl    = {https://dblp.org/rec/conf/sigmod/KumarNP15.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
    @article{DBLP:journals/pvldb/ChenKNP17,
      author    = {Lingjiao Chen and
                   Arun Kumar and
                   Jeffrey F. Naughton and
                   Jignesh M. Patel},
      title     = {Towards Linear Algebra over Normalized Data},
      journal   = {Proc. {VLDB} Endow.},
      volume    = {10},
      number    = {11},
      pages     = {1214--1225},
      year      = {2017},
      url       = {http://www.vldb.org/pvldb/vol10/p1214-chen.pdf},
      doi       = {10.14778/3137628.3137633},
      timestamp = {Sat, 25 Apr 2020 13:59:39 +0200},
      biburl    = {https://dblp.org/rec/journals/pvldb/ChenKNP17.bib},
      bibsource = {dblp computer science bibliography, https://dblp.org}
    }
    
  </textarea>
</body>

</html>
<!-- End Blog Minimal Blocks -->
<!-- Footer -->
<div class="g-pt-50">
  <footer class="g-bg-secondary">
    <div class="g-brd-bottom g-brd-secondary-light-v2 g-py-20">
    </div>
    <div class="container">
      <!-- Footer - Bottom Section -->
      <div class="row align-items-center">
        <div class="col-md-4 g-brd-right--md g-brd-secondary-light-v2 g-mb-30">
          <!-- Copyright -->
          <p class="g-color-secondary-light-v1 g-font-size-12 mb-0">
            © 2022 All Rights Reserved.
          </p>
          <!-- End Copyright -->
        </div>
        <div class="col-md-8 g-brd-right--md g-brd-secondary-light-v2 g-mb-30 text-right">
          <!-- Links -->
          <ul class="list-inline mb-0">
            <li class="list-inline-item g-pl-0 g-pr-10">
              <a class="u-link-v5 g-color-black-opacity-0_5 g-font-size-12" href="contacts.html">
                Contact Us
              </a>
            </li>
            <li class="list-inline-item g-px-10">
              <a class="u-link-v5 g-color-black-opacity-0_5 g-font-size-12">
                Last modified: January 31, 2022
              </a>
            </li>
          </ul>
          <!-- End Links -->
        </div>
      </div>
      <!-- End Footer - Bottom Section -->
    </div>
  </footer>
</div>
<!-- End Footer -->
<!-- JS Global Compulsory -->
<script src="assets/vendor/jquery/jquery.min.js">
</script>
<script src="assets/vendor/jquery-migrate/jquery-migrate.min.js">
</script>
<script src="assets/vendor/jquery.easing/js/jquery.easing.js">
</script>
<script src="assets/vendor/popper.min.js">
</script>
<script src="assets/vendor/bootstrap/bootstrap.min.js">
</script>
<!-- JS Implementing Plugins -->
<script src="assets/vendor/appear.js">
</script>
<script src="assets/vendor/hs-megamenu/src/hs.megamenu.js">
</script>
<script src="assets/vendor/masonry/dist/masonry.pkgd.min.js">
</script>
<script src="assets/vendor/imagesloaded/imagesloaded.pkgd.min.js">
</script>
<script src="assets/vendor/cubeportfolio-full/cubeportfolio/js/jquery.cubeportfolio.min.js">
</script>
<script src="assets/vendor/slick-carousel/slick/slick.js">
</script>
<!-- JS Unify -->
<script src="assets/js/hs.core.js">
</script>
<script src="assets/js/components/hs.header.js">
</script>
<script src="assets/js/helpers/hs.hamburgers.js">
</script>
<script src="assets/js/components/hs.dropdown.js">
</script>
<script src="assets/js/components/hs.tabs.js">
</script>
<script src="assets/js/components/hs.cubeportfolio.js">
</script>
<script src="assets/js/components/hs.onscroll-animation.js">
</script>
<script src="assets/js/components/hs.go-to.js">
</script>
<script src="assets/js/components/hs.carousel.js">
</script>
<!-- JS Customization -->
<script src="assets/js/custom.js">
</script>

<script src="assets/js/parser.js"></script>

<script>
  const bib = $("#bibtex_input").text()
  // console.log(bib)

  const bibFile = parseBibFile(bib)

  const entries_sorted = bibFile.entries_raw.sort((a, b) => {
    const a_au = bibFile.getEntry(a._id).getField("author").authors$.map(author => author.lastNames).join(" ")
    const b_au = bibFile.getEntry(b._id).getField("author").authors$.map(author => author.lastNames).join(" ")
    return a_au.localeCompare(b_au);
  })

  let keys_sorted = entries_sorted.map(e => e._id.toUpperCase())

  var all = $("citation").map(function () {
    return this.innerHTML.toUpperCase();
  }).get();
  // console.log(all)
  keys_sorted = keys_sorted.filter(k => all.findIndex(a => a == k) !== -1)
  // console.log(keys_sorted)
  // console.log(keys)


  $("citation").each(function (index) {
    // console.log(index + ": " + $( this ).text())
    const id = $(this).text().toUpperCase();

    // console.log(id)

    const idx = keys_sorted.findIndex(k => k == id)

    $(this).replaceWith(`<a href="#${id}">${idx + 1}</a>`)
    $(this).css("display", "inline-block")
  })
</script>

<script src="assets/js/bibtex_js.js"></script>

<!-- JS Plugins Init. -->
<script>
  $(document).on('ready', function () {
    // initialization of tabs
    $.HSCore.components.HSTabs.init('[role="tablist"]');

    // initialization of scroll animation
    $.HSCore.components.HSOnScrollAnimation.init('[data-animation]');

    // initialization of go to
    $.HSCore.components.HSGoTo.init('.js-go-to');

    // initialization of HSDropdown component
    $.HSCore.components.HSDropdown.init($('[data-dropdown-target]'), {
      afterOpen: function () {
        $(this).find('input[type="search"]').focus();
      }
    });

  });



  $(window).on('load', function () {
    // initialization of header
    $.HSCore.components.HSHeader.init($('#js-header'));
    $.HSCore.helpers.HSHamburgers.init('.hamburger');

    // initialization of HSMegaMenu component
    $('.js-mega-menu').HSMegaMenu({
      event: 'hover',
      pageContainer: $('.container'),
      breakpoint: 991
    });

    // initialization of masonry
    $('.masonry-grid').imagesLoaded().then(function () {
      $('.masonry-grid').masonry({
        columnWidth: '.masonry-grid-sizer',
        itemSelector: '.masonry-grid-item',
        percentPosition: true
      });
    });

    // initialization of cubeportfolio
    $.HSCore.components.HSCubeportfolio.init('.cbp');
  });

  $(window).on('resize', function () {
    setTimeout(function () {
      $.HSCore.components.HSTabs.init('[role="tablist"]');
    }, 200);
  });
</script>